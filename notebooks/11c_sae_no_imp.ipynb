{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying a sparse 1 layer autoencoder, then a probe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "\n",
    "from typing import Optional, List, Dict, Union\n",
    "from jaxtyping import Float\n",
    "from torch import Tensor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import Tensor\n",
    "from torch import optim\n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset\n",
    "\n",
    "from pathlib import Path\n",
    "from einops import rearrange\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    AutoConfig,\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_config,\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    TaskType,\n",
    "    LoftQConfig,\n",
    "    IA3Config,\n",
    ")\n",
    "from pathlib import Path\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "logger.add(os.sys.stderr, format=\"{time} {level} {message}\", level=\"INFO\")\n",
    "\n",
    "# load my code\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "from src.config import ExtractConfig\n",
    "from src.llms.load import load_model\n",
    "from src.helpers.torch_helpers import clear_mem\n",
    "from src.llms.phi.model_phi import PhiForCausalLMWHS\n",
    "from src.eval.ds import filter_ds_to_known\n",
    "from src.datasets.act_dm import ActivationDataModule\n",
    "\n",
    "# plt.style.use(\"ggplot\")\n",
    "# plt.style.use(\"seaborn-v0_8\")\n",
    "import seaborn as sns\n",
    "sns.set_theme('paper')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paramsnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "\n",
    "# cfg = ExtractConfig(\n",
    "#     # model=\"microsoft/phi-2\",\n",
    "#     # # batch_size=1,\n",
    "#     # prompt_format=\"phi\",\n",
    "# )\n",
    "# cfg\n",
    "\n",
    "# params\n",
    "batch_size = 32\n",
    "lr = 1e-3 # at 3e-4 I get nan\n",
    "wd = 0 # 1e-5\n",
    "\n",
    "MAX_ROWS = 2000\n",
    "\n",
    "SKIP=5 # skip initial N layers\n",
    "STRIDE=4 # skip every N layers\n",
    "DECIMATE=1 # discard N features for speed\n",
    "\n",
    "device = \"cuda:0\"\n",
    "max_epochs = 44\n",
    "\n",
    "l1_coeff = 0.5 # 0.5  # neel uses 3e-4 ! https://github.dev/neelnanda-io/1L-Sparse-Autoencoder/blob/bcae01328a2f41d24bd4a9160828f2fc22737f75/utils.py#L106, but them they sum l1 where mean l2\n",
    "    # x_feats=x_feats. other use 1e-1\n",
    "\n",
    "\n",
    "BASE_FOLDER = Path(\"/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/notebooks/lightning_logs/version_24/\")\n",
    "layers_names = (\n",
    "    'fc1', 'Wqkv',\n",
    "                 'fc2', 'out_proj')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/notebooks/lightning_logs/version_24/hidden_states/.ds/ds_valtest_8b8fd6070504d5ef'),\n",
       " PosixPath('/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/notebooks/lightning_logs/version_24/hidden_states/.ds/ds_OOD_a41d3a61513ade30'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load hidden state from a previously loaded adapter\n",
    "# the columns with _base are from the base model, and adapt from adapter\n",
    "# FROM TRAINING TRUTH\n",
    "f1_val = next(iter(BASE_FOLDER.glob('hidden_states/.ds/ds_valtest_*')))\n",
    "f1_ood = next(iter(BASE_FOLDER.glob('hidden_states/.ds/ds_OOD_*')))\n",
    "f1_val, f1_ood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # insample_datasets = list(set(ds_val['ds_string_base']))\n",
    "# # outsample_datasets = list(set(ds_ood['ds_string_base']))\n",
    "# # print(insample_datasets, outsample_datasets)\n",
    "# from src.datasets.act_dm import ActivationDataModule, SharedDataset\n",
    "\n",
    "\n",
    "# class ActivationDataModule2(ActivationDataModule):\n",
    "#     def to_tds(self, ds, name):\n",
    "#         \"\"\"huggingface dataset to pytorch.\"\"\"\n",
    "#         h = self.hparams\n",
    "#         # 4x faster if we make it a tensor ourselves\n",
    "#         ds = ds.with_format(None)\n",
    "#         tds = torch.utils.data.TensorDataset(\n",
    "#             torch.FloatTensor(ds['X'][..., 0]), torch.FloatTensor(ds['y']))\n",
    "        \n",
    "#         # this shared dataset is 10x faster with multiple workers\n",
    "#         if h.num_workers>0: \n",
    "#             tds = SharedDataset(tds, f\"{self.hparams.name}_{name}\") \n",
    "#         return tds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select rows are 74.39% based on knowledge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30fc5419858e4400a22ffa503194ab8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/615 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-01-08 06:03:10.884\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.datasets.act_dm\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mconverting datasets this may take a while... ds_valtest_8b8fd6070504d5ef train\u001b[0m\n",
      "2024-01-08T06:03:10.884970+0800 INFO converting datasets this may take a while... ds_valtest_8b8fd6070504d5ef train\n"
     ]
    }
   ],
   "source": [
    "input_columns = ['binary_ans_base', 'binary_ans_adapt' ] + [f'end_residual_{layer}_base' for layer in layers_names] + [f'end_residual_{layer}_adapt' for layer in layers_names]\n",
    "\n",
    "def ds2xy_batched(ds):\n",
    "    data = []\n",
    "    for layer in layers_names:\n",
    "        # Stack the base and adapter representations as a 4th dim\n",
    "        X1 = [ds[f'end_residual_{layer}_base'], ds[f'end_residual_{layer}_adapt']]\n",
    "        X1 = rearrange(X1, 'versions b l f  -> b l f versions')[..., 0]\n",
    "        data.append(X1)\n",
    "    \n",
    "    # concat layers\n",
    "    # x = rearrange(data, 'b parts l f v -> b l (parts f) v')\n",
    "    X = torch.concat(data, dim=2)[:, SKIP::STRIDE, ::DECIMATE]\n",
    "\n",
    "    y = ds['binary_ans_base']-ds['binary_ans_adapt']\n",
    "    return dict(X=X, y=y)\n",
    "\n",
    "\n",
    "\n",
    "def prepare_ds(ds):\n",
    "    \"\"\"\n",
    "    prepare a dataset for training\n",
    "\n",
    "    this should front load much of the computation\n",
    "    it should restrict it to the needed rows X and y\n",
    "    \n",
    "    \"\"\"\n",
    "    ds = (ds\n",
    "          .with_format(\"torch\")\n",
    "          .select_columns(input_columns)\n",
    "          .map(ds2xy_batched, batched=True, batch_size=128,\n",
    "        remove_columns=input_columns)\n",
    "    )\n",
    "    return ds\n",
    "\n",
    "def load_file_to_dm(f, stage):\n",
    "    ds1 = Dataset.from_file(str(f1_val), in_memory=True).with_format(\"torch\")\n",
    "    ds1 = filter_ds_to_known(ds1, verbose=True, true_col='truth')\n",
    "    ds = prepare_ds(ds1)\n",
    "\n",
    "    # limit size\n",
    "    MAX_SAMPLES = min(len(ds), MAX_ROWS*2)\n",
    "    ds = ds.select(range(0, MAX_SAMPLES))\n",
    "\n",
    "    dm = ActivationDataModule(ds, f.stem, batch_size=batch_size, num_workers=0)\n",
    "    dm.setup(stage)\n",
    "    dm.dm_orig = ds1\n",
    "    return dm\n",
    "\n",
    "\n",
    "dm = load_file_to_dm(f1_val, 'train')\n",
    "dm_ood = load_file_to_dm(f1_ood, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dl_train = dm.train_dataloader()\n",
    "dl_val = dm.val_dataloader()\n",
    "dl_test = dm.test_dataloader()\n",
    "dl_ood = dm_ood.all_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with dataloading speeds:\n",
    "- does it help to save the Xy dataset to disc, then load, while keeping in mem?. no not faster at all\n",
    "- does it help to use num_workers > 0? yes 3x faster\n",
    "- the shared dataset wrapper is 10x faster, and less mem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get importance matrix from adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.probes.importance_matrix import get_importance_matrix\n",
    "\n",
    "\n",
    "# f = f\"{BASE_FOLDER}/checkpoint_last/adapter_model.safetensors\"\n",
    "# importance_matrix = get_importance_matrix(f, layers=layers_names)[SKIP::STRIDE, ::DECIMATE]\n",
    "# plt.hist(importance_matrix.flatten(), bins=155);\n",
    "importance_matrix = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((importance_matrix>0)*1.0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_matrix.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test2 = dm.datasets['test']\n",
    "shape1 = ds_test2[0][0].shape\n",
    "shape2= importance_matrix.shape\n",
    "np.testing.assert_equal(shape1, shape2, err_msg=\"shape mismatch between ds and importance matrix\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from src.vae.conv_inception import PLAE, LinBnDrop, PLBase, recursive_requires_grad, accuracy, auroc\n",
    "\n",
    "from src.vae.sae import AutoEncoder, AutoEncoderConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PLAE(PLBase):\n",
    "    def __init__(\n",
    "        self,\n",
    "        c_in,\n",
    "        steps_per_epoch,\n",
    "        max_epochs,\n",
    "        # depth=0,\n",
    "        lr=4e-3,\n",
    "        weight_decay=1e-9,\n",
    "        # hs=64,\n",
    "        n_latent=32,\n",
    "        l1_coeff=1,\n",
    "        dropout=0,\n",
    "        importance_matrix=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(steps_per_epoch=steps_per_epoch, max_epochs=max_epochs, lr=lr, weight_decay=weight_decay)\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        n_layers, n_channels = c_in\n",
    "        self.ae_cfg = AutoEncoderConfig(\n",
    "            n_instances=n_layers,\n",
    "            n_input_ae=n_channels,\n",
    "            n_hidden_ae=n_latent,\n",
    "            tied_weights=False,\n",
    "            l1_coeff=l1_coeff,\n",
    "        )\n",
    "\n",
    "        self.ae = AutoEncoder(\n",
    "            self.ae_cfg,\n",
    "            importance_matrix=importance_matrix,\n",
    "        )\n",
    "        \n",
    "        n = n_latent * n_layers\n",
    "        self.head = nn.Sequential(\n",
    "            LinBnDrop(n, n, bn=False),\n",
    "            LinBnDrop(n, n // 4, dropout=dropout, bn=False),\n",
    "            LinBnDrop(n // 4, n // 12, bn=False),\n",
    "            nn.Linear(n // 12, 1),\n",
    "            # nn.Tanh(),\n",
    "        )\n",
    "        self._ae_mode = True\n",
    "\n",
    "    def ae_mode(self, mode=0):\n",
    "        \"\"\"\n",
    "        mode 0, train the ae\n",
    "        mode 1, train only the prob\n",
    "        mode 2, train both\n",
    "        \"\"\"\n",
    "        if mode==0:\n",
    "            print('training ae')\n",
    "        elif mode==1:\n",
    "            print('training probe')\n",
    "        elif mode==2:\n",
    "            print('training both ae and probe')\n",
    "        self._ae_mode = mode\n",
    "        recursive_requires_grad(self.ae, mode in [0, 2])\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.ndim == 4:\n",
    "            x = x.squeeze(3)\n",
    "        # x = rearrange(x, \"b l h -> b h l\")\n",
    "        # if not self._ae_mode:\n",
    "        #     with torch.no_grad():\n",
    "        #         l1_loss, l2_loss, loss, latent, h_rec = self.ae(x)\n",
    "        # else:\n",
    "        l1_loss, l2_loss, loss, latent, h_rec = self.ae(x)\n",
    "\n",
    "        latent2 = rearrange(latent, \"b l h -> b (l h)\")\n",
    "        pred = self.head(latent2).squeeze(1)\n",
    "        return dict(\n",
    "            pred=pred,\n",
    "            l1_loss=l1_loss,\n",
    "            l2_loss=l2_loss,\n",
    "            loss=loss,\n",
    "            latent=latent,\n",
    "            h_rec=h_rec,\n",
    "        )\n",
    "\n",
    "    def _step(self, batch, batch_idx, stage=\"train\"):        \n",
    "        if stage == \"train\":\n",
    "            # Normalize the decoder weights before each optimization step\n",
    "            self.ae.normalize_decoder()\n",
    "\n",
    "\n",
    "        device = next(self.parameters()).device\n",
    "        x, y = batch # batch['X'], batch['y']\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        x0 = x#[..., 0]\n",
    "        # x1 = x[..., 1]\n",
    "        info0 = self(x0)\n",
    "        # info1 = self(x1)\n",
    "        # ypred1 = info1[\"pred\"]\n",
    "        logits = info0[\"pred\"]\n",
    "        y_probs = F.sigmoid(logits)\n",
    "        y_cls = y_probs > 0.5\n",
    "\n",
    "        if stage == \"pred\":\n",
    "            return (y_probs).float()\n",
    "        \n",
    "        pred_loss = F.binary_cross_entropy_with_logits(logits, (y>0.).float())\n",
    "\n",
    "        # pred_loss = F.smooth_l1_loss(ypred0, y)\n",
    "        rec_loss = info0[\"loss\"] \n",
    "        l1_loss = info0[\"l1_loss\"].mean()\n",
    "        l2_loss = info0[\"l2_loss\"].mean()\n",
    "\n",
    "        self.log(\n",
    "            f\"{stage}/auroc\",\n",
    "            auroc(y_probs, y > 0, \"binary\"),\n",
    "            on_epoch=True,\n",
    "            on_step=False,\n",
    "        )\n",
    "        self.log(\n",
    "            f\"{stage}/acc\",\n",
    "            accuracy(y_cls, y > 0, \"binary\"),\n",
    "            on_epoch=True,\n",
    "            on_step=False,\n",
    "        )\n",
    "        self.log(\n",
    "            f\"{stage}/loss_pred\",\n",
    "            float(pred_loss),\n",
    "            on_epoch=True,\n",
    "            on_step=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        self.log(\n",
    "            f\"{stage}/loss_rec\",\n",
    "            float(rec_loss),\n",
    "            on_epoch=True,\n",
    "            on_step=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        self.log(f\"{stage}/l1_loss\", l1_loss, on_epoch=True, on_step=False)\n",
    "        self.log(f\"{stage}/l2_loss\", l2_loss, on_epoch=True, on_step=False)\n",
    "        self.log(\n",
    "            f\"{stage}/n\",\n",
    "            float(len(y)),\n",
    "            on_epoch=True,\n",
    "            on_step=False,\n",
    "            reduce_fx=torch.sum,\n",
    "        )\n",
    "        if self._ae_mode == 0:\n",
    "            assert torch.isfinite(rec_loss), \"rec_loss is not finite\"\n",
    "            return rec_loss\n",
    "        elif self._ae_mode == 1:\n",
    "            assert torch.isfinite(pred_loss), \"pred_loss is not finite\"\n",
    "            return pred_loss\n",
    "        elif self._ae_mode == 2:\n",
    "            # , train/loss_pred_epoch=0.0195, train/loss_rec_epoch=169.0\n",
    "            assert torch.isfinite(pred_loss), \"pred_loss is not finite\"\n",
    "            assert torch.isfinite(rec_loss), \"rec_loss is not finite\"\n",
    "            return pred_loss * 50000 + rec_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(len(dl_train), len(dl_val))\n",
    "b = next(iter(dl_train))\n",
    "x, y = b # b['X'], b['y']\n",
    "print(x.shape, \"x\")\n",
    "if x.ndim == 3:\n",
    "    x = x.unsqueeze(-1)\n",
    "c_in = x.shape[1:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEST\n",
    "# for b in tqdm(dl_train):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # oh no, this is very slow\n",
    "# g = iter(dl_train)\n",
    "# b = next(g)\n",
    "# b = next(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net = PLAE(\n",
    "    c_in=c_in,\n",
    "    steps_per_epoch=len(dl_train),\n",
    "    max_epochs=max_epochs,\n",
    "    lr=lr,\n",
    "    weight_decay=wd,\n",
    "    # hs=64,\n",
    "    dropout=0,\n",
    "    n_latent=256, # there will be layers * n_latent latent features\n",
    "    l1_coeff=l1_coeff, \n",
    "    importance_matrix=importance_matrix,\n",
    ")\n",
    "print(c_in)\n",
    "x1= x[..., 0]\n",
    "with torch.no_grad():\n",
    "    y = net(x1)\n",
    "{k: v.abs().mean() for k, v in y.items()}, {k: v.shape for k, v in y.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "14341/c_in[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(net, input_data=x1, depth=4)  # input_size=(batch_size, 1, 28, 28))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# for b in tqdm(dl_train):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    o = net.predict_step(b)\n",
    "    l1_loss, l2_loss, loss, acts, h_reconstructed = net.ae(b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1_coeff = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((acts>1)*1.0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_loss, l2_loss/l1_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.helpers.lightning import read_metrics_csv, plot_hist, rename_pl_test_results\n",
    "\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.ae_mode(0)\n",
    " \n",
    "lr_logger = LearningRateMonitor(logging_interval='step')\n",
    "trainer1 = pl.Trainer(\n",
    "    precision=\"16-mixed\",\n",
    "    gradient_clip_val=20,\n",
    "    # devices=2,\n",
    "    accelerator=\"auto\",\n",
    "    devices=\"1\",\n",
    "    max_epochs=max_epochs,# * VAE_EPOCH_MULT,\n",
    "    log_every_n_steps=1,\n",
    "    # enable_progress_bar=False, enable_model_summary=False\n",
    "    callbacks=[lr_logger],\n",
    ")\n",
    "\n",
    "# LOAD_CHECKPONT = Path('/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/notebooks/lightning_logs/version_52/1_ae.ckpt')\n",
    "LOAD_CHECKPONT = None\n",
    "if LOAD_CHECKPONT:\n",
    "    PLAE.load_from_checkpoint(LOAD_CHECKPONT)\n",
    "else:\n",
    "    trainer1.fit(model=net, train_dataloaders=dl_train, \n",
    "                 val_dataloaders=dl_val # FIXME why does this slow it down with multiple processes?\n",
    "                );\n",
    "\n",
    "    df_hist, df_hist_step = read_metrics_csv(trainer1.logger.experiment.metrics_file_path)\n",
    "    plot_hist(df_hist, ['l2_loss', 'l1_loss', 'loss_rec'], logy=True)\n",
    "    plt.show()\n",
    "    plot_hist(df_hist_step, ['loss_rec_step'], logy=True)\n",
    "\n",
    "    display(df_hist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist, df_hist_step = read_metrics_csv(trainer1.logger.experiment.metrics_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the LR\n",
    "df_hist, df_hist_step = read_metrics_csv(trainer1.logger.experiment.metrics_file_path)\n",
    "df_hist['lr-AdamW'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l2_loss ~= l1_loss * l1_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist[['train/l2_loss','train/l1_loss']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('l1 coeff should be approx')\n",
    "ratio = df_hist['train/l2_loss']/df_hist['train/l1_loss']\n",
    "ratio = ratio[np.isfinite(ratio)]\n",
    "ratio.mean()/l1_coeff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((latent>0)*1.0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5/10 [00:04<00:04, 1.10it/s, v_num=295, val/loss_pred=0.0849, val/loss_rec=9.58e+5, train/loss_pred=0.350, train/loss_rec=9.8e+5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize latent space\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "def plot_latent(latent):\n",
    "\n",
    "    # plot image of latent space\n",
    "    vmax = latent.abs().max()\n",
    "    for i in range(4):\n",
    "        plt.subplot(2, 2, i + 1)\n",
    "        vmax = latent[i].abs().max()\n",
    "        plt.imshow(\n",
    "            latent[i],\n",
    "            cmap=cm.coolwarm,\n",
    "            interpolation=\"none\",\n",
    "            aspect=\"auto\",\n",
    "            vmin=-vmax,\n",
    "            vmax=vmax,\n",
    "        )\n",
    "        plt.xlabel(\"layer\")\n",
    "        plt.ylabel(\"neuron\")\n",
    "        if i < 2:\n",
    "            plt.xlabel(\"\")\n",
    "            plt.xticks([])\n",
    "        if i % 2 == 1:\n",
    "            plt.ylabel(\"\")\n",
    "            plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.colorbar()\n",
    "    # plt.colorbar()\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "    plt.show()\n",
    "\n",
    "    # histogram\n",
    "    latentf = rearrange(latent, \"b n l -> (b n) l\").flatten()\n",
    "    vmax = (latentf.abs().mean() + 5 * latentf.abs().std()).item()\n",
    "    plt.hist(latentf, bins=55, range=[-vmax, vmax], histtype=\"step\")\n",
    "    plt.title(\"latents by layer\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "latent = y[\"latent\"].cpu()  # .reshape(64, 24, 12) # [Batch, Latent, Layer]\n",
    "plot_latent(latent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent.shape, latent.diff(dim=1).std(), latent.std(), latent.diff(dim=2).std(), 16*7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # net.save_checkpoint\n",
    "# f = Path(trainer1.log_dir)/\"1_ae.ckpt\"\n",
    "# trainer1.save_checkpoint(f)\n",
    "# # PosixPath('/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/notebooks/lightning_logs/version_52/1_ae.ckpt')\n",
    "# f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.configure_optimizers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for b in tqdm(dl_train):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for b in tqdm(dl_train):\n",
    "    y = net.predict_step(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # debug\n",
    "# with torch.no_grad():\n",
    "#     b = next(iter(dl_train))\n",
    "#     y = net.predict_step(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.ae_mode(1)\n",
    "trainer2 = pl.Trainer(\n",
    "    # precision=\"16-mixed\",\n",
    "    gradient_clip_val=20,\n",
    "    max_epochs=max_epochs,\n",
    "    log_every_n_steps=1,\n",
    "    # enable_progress_bar=False, enable_model_summary=False\n",
    "    # callbacks=[lr_logger],\n",
    ")\n",
    "trainer2.fit(model=net, train_dataloaders=dl_train, \n",
    "             val_dataloaders=dl_val\n",
    "             );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist, _ = read_metrics_csv(trainer2.logger.experiment.metrics_file_path)\n",
    "plot_hist(df_hist, ['loss_pred_epoch', 'auroc'])\n",
    "df_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "# print(f\"training with x_feats={x_feats} with c={c}\")\n",
    "rs = trainer2.test(net, dataloaders=[dl_train, dl_val, dl_test, dl_ood])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testval_metrics = calc_metrics(dm, trainer2, net, use_val=True)\n",
    "rs = rename_pl_test_results(rs, [\"train\", \"val\", \"test\", \"ood\"])\n",
    "# rs['test'] = {**rs['test'], **test_metrics}\n",
    "# rs[\"test\"][\"acc_lie_lie\"] = testval_metrics[\"acc_lie_lie\"]\n",
    "rs[\"testval_metrics\"] = rs[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### how well does it generalize to other datasets?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"training with x_feats={x_feats} with c={c}\")\n",
    "rs2 = trainer1.test(net, dataloaders=[dl_ood])\n",
    "rs2 = rename_pl_test_results(rs2, ks=[\"ood\"])\n",
    "\n",
    "# testval_metrics2 = calc_metrics(dm_ood, trainer1, net, use_val=True)\n",
    "# rs[\"ood\"][\"acc_lie_lie\"] = testval_metrics2[\"acc_lie_lie\"]\n",
    "# rs[\"ood_metrics\"] = rs2[\"ood\"]\n",
    "# rs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train end-to-end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.ae_mode(2)\n",
    "trainer3 = pl.Trainer(\n",
    "    precision=\"16-mixed\",\n",
    "    gradient_clip_val=20,\n",
    "    max_epochs=max_epochs,\n",
    "    log_every_n_steps=3,\n",
    "    # enable_progress_bar=False, enable_model_summary=False\n",
    ")\n",
    "trainer3.fit(model=net, train_dataloaders=dl_train, val_dataloaders=dl_val)\n",
    "1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds2df(dm.dm_orig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.eval.ds import ds2df\n",
    "\n",
    "def get_acc_subset(df, query, verbose=True):\n",
    "    assert (df['y'].mean()<0).any(), 'y should be [-1, 1]'\n",
    "    assert (df['y'].mean()>-1).all(), 'y should be [-1, 1]'\n",
    "    assert (df['y'].mean()<1).all(), 'y should be [-1, 1]'\n",
    "    assert (df['probe_pred'].mean()>0).all(), 'pred should be [0,1]'\n",
    "    assert (df['probe_pred'].mean()<1).all(), 'pred should be [0,1]'\n",
    "\n",
    "    if query:\n",
    "        df = df.query(query)\n",
    "    # df[\"probe_cls\"] = df[\"probe_pred\"] > 0.5\n",
    "    acc = ((df[\"probe_pred\"]>0.5) == (df[\"y\"]>0)).mean()\n",
    "    if verbose:\n",
    "        print(f\"acc={acc:2.2%},\\tn={len(df)},\\t[{query}] \")\n",
    "    return acc\n",
    "\n",
    "\n",
    "def calc_metrics(dm, trainer, net, use_val=False, verbose=True):\n",
    "    dl_test = dm.test_dataloader()\n",
    "    rt = trainer.predict(net, dataloaders=dl_test)\n",
    "    y_test_pred = np.concatenate(rt)\n",
    "    splits = dm.splits[\"test\"]\n",
    "    df = ds2df(dm.dm_orig).rename(columns=lambda s:s.replace('_base',''))\n",
    "    # print(df)\n",
    "    df['y'] = dm.ds['y']\n",
    "\n",
    "    df_test = df.iloc[splits[0] : splits[1]].copy()\n",
    "    df_test[\"probe_pred\"] = y_test_pred\n",
    "    \n",
    "\n",
    "    if use_val:\n",
    "        dl_val = dm.val_dataloader()\n",
    "        rv = trainer.predict(net, dataloaders=dl_val)\n",
    "        y_val_pred = np.concatenate(rv)\n",
    "        splits = dm.splits[\"val\"]\n",
    "        df_val = df.iloc[splits[0] : splits[1]].copy()\n",
    "        df_val[\"probe_pred\"] = y_val_pred\n",
    "\n",
    "        df_test = pd.concat([df_val, df_test])\n",
    "\n",
    "    if verbose:\n",
    "        print(\"probe results on subsets of the data\")\n",
    "    acc = get_acc_subset(df_test, \"\", verbose=verbose)\n",
    "    get_acc_subset(\n",
    "        df_test, \"instructed_to_lie==True\", verbose=verbose\n",
    "    )  # it was ph told to lie\n",
    "    get_acc_subset(\n",
    "        df_test, \"instructed_to_lie==False\", verbose=verbose\n",
    "    )  # it was told not to lie\n",
    "    get_acc_subset(\n",
    "        df_test, \"ans==label_true\", verbose=verbose\n",
    "    )  # the llm gave the true ans\n",
    "    get_acc_subset(\n",
    "        df_test, \"ans==label_instructed\", verbose=verbose\n",
    "    )  # the llm gave the desired ans\n",
    "    acc_lie_lie = get_acc_subset(\n",
    "        df_test, \"instructed_to_lie==True & ans==label_instructed\", verbose=verbose\n",
    "    )  # it was told to lie, and it did lie\n",
    "    acc_lie_truth = get_acc_subset(\n",
    "        df_test, \"instructed_to_lie==True & ans!=label_instructed\", verbose=verbose\n",
    "    )\n",
    "\n",
    "    a = get_acc_subset(\n",
    "        df_test, \"instructed_to_lie==False & ans==label_instructed\", verbose=False\n",
    "    )\n",
    "    b = get_acc_subset(\n",
    "        df_test, \"instructed_to_lie==False & ans!=label_instructed\", verbose=False\n",
    "    )\n",
    "    c = get_acc_subset(\n",
    "        df_test, \"instructed_to_lie==True & ans==label_instructed\", verbose=False\n",
    "    )\n",
    "    d = get_acc_subset(\n",
    "        df_test, \"instructed_to_lie==True & ans!=label_instructed\", verbose=False\n",
    "    )\n",
    "    d1 = pd.DataFrame(\n",
    "        [[a, b], [c, d]],\n",
    "        index=[\"instructed_to_lie==False\", \"instructed_to_lie==True\"],\n",
    "        columns=[\"ans==label_instructed\", \"ans!=label_instructed\"],\n",
    "    )\n",
    "    d1 = pd.DataFrame(\n",
    "        [[a, b], [c, d]],\n",
    "        index=[\"tell a truth\", \"tell a lie\"],\n",
    "        columns=[\"did\", \"didn't\"],\n",
    "    )\n",
    "    d1.index.name = \"instructed to\"\n",
    "    d1.columns.name = \"llm gave\"\n",
    "    print(\"probe accuracy for quadrants\")\n",
    "    display(d1.round(2))\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"⭐PRIMARY METRIC⭐ acc={acc:2.2%} from probe\")\n",
    "        print(f\"⭐SECONDARY METRIC⭐ acc_lie_lie={acc_lie_lie:2.2%} from probe\")\n",
    "    return dict(acc=acc, acc_lie_lie=acc_lie_lie, acc_lie_truth=acc_lie_truth, df_test=df_test)\n",
    "\n",
    "\n",
    "# r = testval_metrics = calc_metrics(dm, trainer3, net, use_val=True)\n",
    "# r['df_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at hist\n",
    "df_hist, _ = read_metrics_csv(trainer3.logger.experiment.metrics_file_path)\n",
    "plot_hist(df_hist, ['loss_pred', 'acc'])\n",
    "\n",
    "# predict\n",
    "# dl_test = dm.test_dataloader()\n",
    "# print(f\"training with x_feats={x_feats} with c={c}\")\n",
    "rs = trainer3.test(net, dataloaders=[dl_train, dl_val, dl_test, dl_ood])\n",
    "\n",
    "testval_metrics = calc_metrics(dm, trainer3, net, use_val=True)\n",
    "rs = rename_pl_test_results(rs, [\"train\", \"val\", \"test\", \"ood\"])\n",
    "# rs['test'] = {**rs['test'], **test_metrics}\n",
    "rs[\"test\"][\"acc_lie_lie\"] = testval_metrics[\"acc_lie_lie\"]\n",
    "rs[\"testval_metrics\"] = rs[\"test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testval_metrics = calc_metrics(dm, trainer3, net, use_val=True)\n",
    "rs = rename_pl_test_results(rs, [\"train\", \"val\", \"test\", \"ood\"])\n",
    "# rs['test'] = {**rs['test'], **test_metrics}\n",
    "rs[\"test\"][\"acc_lie_lie\"] = testval_metrics[\"acc_lie_lie\"]\n",
    "rs[\"testval_metrics\"] = rs[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"training with x_feats={x_feats} with c={c}\")\n",
    "rs2 = trainer3.test(net, dataloaders=[dl_ood])\n",
    "rs2 = rename_pl_test_results(rs2, ks=[\"ood\"])\n",
    "\n",
    "testval_metrics2 = calc_metrics(dm_ood, trainer3, net, use_val=True)\n",
    "rs[\"ood\"][\"acc_lie_lie\"] = testval_metrics2[\"acc_lie_lie\"]\n",
    "rs[\"ood_metrics\"] = rs2[\"ood\"]\n",
    "rs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
