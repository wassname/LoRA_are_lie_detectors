{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This nb is to prototype and compare probes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TQDM_DISABLE'] = '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "from typing import Optional, List, Dict, Union\n",
    "from jaxtyping import Float\n",
    "from torch import Tensor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import Tensor\n",
    "from torch import optim\n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset\n",
    "\n",
    "from pathlib import Path\n",
    "from einops import rearrange\n",
    "\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "logger.add(os.sys.stderr, format=\"{time} {level} {message}\", level=\"INFO\")\n",
    "\n",
    "# # quiet please\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load my code\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from src.datasets.dm import DeceptionDataModule\n",
    "from src.models.pl_lora_ft import AtapterFinetuner\n",
    "\n",
    "from src.config import ExtractConfig\n",
    "from src.prompts.prompt_loading import load_preproc_dataset, load_preproc_datasets\n",
    "from src.models.load import load_model\n",
    "from src.helpers.torch_helpers import clear_mem\n",
    "from src.models.phi.model_phi import PhiForCausalLMWHS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# plt.style.use(\"ggplot\")\n",
    "\n",
    "plt.style.use(['seaborn-v0_8', 'seaborn-v0_8-paper'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 20\n",
    "batch_size=16\n",
    "verbose = False\n",
    "MAX_SAMPLES = 1000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load previously made datasets of hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -altrh '/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/.ds/'\n",
    "\n",
    "# !ls -altrh '/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/.ds/ds_valtest_8c031b4aa03ae4d2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_ood = '/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/.ds/ds_OOD_4a1b0db1fd6f7026'\n",
    "f1_val = '/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/.ds/ds_valtest_7bf5202bdaa0342b'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_val = Dataset.from_file(f1_val).with_format(\"torch\")\n",
    "\n",
    "ds_oos = Dataset.from_file(f1_ood).with_format(\"torch\")\n",
    "\n",
    "ds_out1 = datasets.interleave_datasets([ds_val, ds_val])\n",
    "ds_out = ds_out1.select(range(MAX_SAMPLES))\n",
    "ds_out1, ds_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.eval.interventions import check_lr_intervention_predictive\n",
    "from src.eval.labels import ranking_truth_telling, ds2label_model_truth\n",
    "from src.eval.ds import filter_ds_to_known\n",
    "\n",
    "from src.models.pl_ranking_probe import PLConvProbeLinear\n",
    "from src.helpers.lightning import read_metrics_csv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from src.helpers.pandas_classification_report import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds_known = filter_ds_to_known(ds_out, verbose=True)\n",
    "hs_normal = ds_out['end_residual_stream_base']\n",
    "hs_intervene = ds_out['end_residual_stream_adapt']\n",
    "label_fn = ranking_truth_telling\n",
    "hs = hs_normal - hs_intervene\n",
    "y = label_fn(ds_out)\n",
    "y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = check_lr_intervention_predictive(hs, y, verbose=True)\n",
    "r['cr']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = check_lr_intervention_predictive(hs, y, verbose=True, scale=False)\n",
    "# r['cr']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv mse ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_convrank_intervention_predictive(hs, y, verbose=True):\n",
    "\n",
    "\n",
    "def dist_truth_telling(ds):\n",
    "    \"\"\"label whether the adapter or the base model were more truthfull.\"\"\"\n",
    "    return ds['correct_truth_telling_adapt'] - ds['correct_truth_telling_base']\n",
    "\n",
    "y = dist_truth_telling(ds_out)\n",
    "X = torch.stack([hs_normal,hs_intervene], 1)\n",
    "X_train0, X_val0, X_train1, X_val1, y_train, y_val = train_test_split(hs_normal, hs_intervene, y, test_size=0.5, random_state=42)\n",
    "\n",
    "to_ds = lambda hs0, hs1, y: TensorDataset(hs0, hs1, y)\n",
    "dl_train = DataLoader(to_ds(X_train0, X_train1, y_train), batch_size=batch_size, shuffle=True)\n",
    "dl_val = DataLoader(to_ds(X_val0, X_val1, y_val), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "x0, x1,y1 = next(iter(dl_train))\n",
    "c_in = x1.shape[1:]\n",
    "net = PLConvProbeLinear(c_in, total_steps=max_epochs * len(dl_train), depth=3, lr=4e-3, weight_decay=1e-5, hs=32, dropout=0.1)\n",
    "\n",
    "from torchinfo import summary\n",
    "summary(net, input_data=x1) # input_size=(batch_size, 1, 28, 28))\n",
    "\n",
    "\n",
    "trainer1 = pl.Trainer(\n",
    "    gradient_clip_val=20,\n",
    "    # accelerator=\"auto\",\n",
    "    # devices=\"1\",\n",
    "    max_epochs=max_epochs,\n",
    "    log_every_n_steps=1,\n",
    "    enable_progress_bar=verbose,\n",
    "      enable_model_summary=verbose\n",
    ")\n",
    "trainer1.fit(model=net, train_dataloaders=dl_train, val_dataloaders=dl_val);\n",
    "\n",
    "df_hist, df_hist_step  = read_metrics_csv(trainer1.logger.experiment.metrics_file_path)\n",
    "\n",
    "df_hist[['val/acc', 'train/acc']].plot()\n",
    "df_hist[['val/loss', 'train/loss']].plot()\n",
    "# df_hist_step[['val/acc', 'train/acc']].plot(style=\".\")\n",
    "# df_hist_step[['val/loss', 'train/loss']].plot(style=\".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_hist[['val/acc', 'train/acc']].plot()\n",
    "# df_hist[['val/loss', 'train/loss']].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r = trainer1.predict(net, dataloaders=dl_val)\n",
    "y_pred_raw = torch.cat(r).flatten()\n",
    "# y_pred_prob = (y_pred_raw+1)/2\n",
    "y_pred_prob = (torch.tanh(y_pred_raw)+1)/2\n",
    "y_pred = y_pred_raw > 0.\n",
    "y_val2 = y_val > 0.\n",
    "\n",
    "score = roc_auc_score(y_val2, y_pred_prob)\n",
    "print(score)\n",
    "target_names = [0, 1]\n",
    "cm = confusion_matrix(y_val2, y_pred, target_names=target_names, normalize='true')\n",
    "cr = classification_report(y_val2, y_pred, target_names=target_names)\n",
    "print(cm)\n",
    "print(cr)\n",
    "# return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_kwargs = dict(lw=2, alpha=0.75, histtype=\"step\", bins=26, range=(-2,2))\n",
    "# plt.hist(y_pred_prob, label='prob', **hist_kwargs, )\n",
    "# plt.hist(y_val2,label='pred',  **hist_kwargs,)\n",
    "# plt.hist(y_pred, label='truth',  **hist_kwargs,)\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# plt.hist(y_pred_raw, label='pred',  **hist_kwargs,)\n",
    "# plt.hist(y_val,  label='truth',  **hist_kwargs,)\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv bool ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional import accuracy, auroc, f1_score, jaccard_index, dice\n",
    "from random import random as rand\n",
    "\n",
    "class PLConvProbeBoolRank(PLConvProbeLinear):\n",
    "    def _step(self, batch, batch_idx, stage='train'):\n",
    "        x0, x1, y = batch\n",
    "\n",
    "        if rand()>0.5:\n",
    "            x0, x1 = x1, x0\n",
    "            y = 1-y\n",
    "            \n",
    "        ypred0 = self(x0)\n",
    "        ypred1 = self(x1)\n",
    "        \n",
    "        if stage=='pred':\n",
    "            return (ypred1-ypred0).float()\n",
    "        \n",
    "        ranking_y = (y>0)*2-1 # from 0,1 to -1,1\n",
    "        loss = F.margin_ranking_loss(ypred1, ypred0, ranking_y, margin=1)\n",
    "        # loss = F.smooth_l1_loss(ypred1-ypred0, y)\n",
    "        # self.log(f\"{stage}/loss\", loss)\n",
    "        \n",
    "        y_cls = ypred1>ypred0 # switch2bool(ypred1-ypred0)\n",
    "        self.log(f\"{stage}/acc\", accuracy(y_cls, y>0, \"binary\"), on_epoch=True, on_step=False)\n",
    "        self.log(f\"{stage}/loss\", loss, on_epoch=True, on_step=False)\n",
    "        self.log(f\"{stage}/n\", len(y), on_epoch=True, on_step=False, reduce_fx=torch.sum)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def check_convrank_intervention_predictive(hs, y, verbose=True):\n",
    "\n",
    "\n",
    "def dist_truth_telling(ds):\n",
    "    \"\"\"label whether the adapter or the base model were more truthfull.\"\"\"\n",
    "    return ds['correct_truth_telling_adapt'] > ds['correct_truth_telling_base']\n",
    "\n",
    "y = dist_truth_telling(ds_out)\n",
    "X = torch.stack([hs_normal,hs_intervene], 1)\n",
    "X_train0, X_val0, X_train1, X_val1, y_train, y_val = train_test_split(hs_normal, hs_intervene, y, test_size=0.5, random_state=42)\n",
    "\n",
    "to_ds = lambda hs0, hs1, y: TensorDataset(hs0, hs1, y)\n",
    "dl_train = DataLoader(to_ds(X_train0, X_train1, y_train), batch_size=batch_size, shuffle=True)\n",
    "dl_val = DataLoader(to_ds(X_val0, X_val1, y_val), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "x0, x1,y1 = next(iter(dl_train))\n",
    "c_in = x1.shape[1:]\n",
    "net = PLConvProbeBoolRank(c_in, total_steps=max_epochs * len(dl_train), depth=3, lr=4e-3, weight_decay=1e-5, hs=16, dropout=0.2)\n",
    "\n",
    "from torchinfo import summary\n",
    "summary(net, input_data=x1) # input_size=(batch_size, 1, 28, 28))\n",
    "\n",
    "\n",
    "trainer1 = pl.Trainer(\n",
    "    gradient_clip_val=20,\n",
    "    # accelerator=\"auto\",\n",
    "    # devices=\"1\",\n",
    "    max_epochs=max_epochs,\n",
    "    log_every_n_steps=1,\n",
    "    enable_progress_bar=verbose,\n",
    "      enable_model_summary=verbose\n",
    ")\n",
    "trainer1.fit(model=net, train_dataloaders=dl_train, val_dataloaders=dl_val);\n",
    "\n",
    "\n",
    "\n",
    "df_hist, df_hist_step  = read_metrics_csv(trainer1.logger.experiment.metrics_file_path)\n",
    "\n",
    "df_hist[['val/acc', 'train/acc']].plot()\n",
    "df_hist[['val/loss', 'train/loss']].plot()\n",
    "# df_hist_step[['val/acc', 'train/acc']].plot(style=\".\")\n",
    "# df_hist_step[['val/loss', 'train/loss']].plot(style=\".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = trainer1.predict(net, dataloaders=dl_val)\n",
    "y_pred_raw = torch.cat(r).flatten()\n",
    "y_pred_prob = (torch.tanh(y_pred_raw)+1)/2\n",
    "y_pred = y_pred_raw > 0.\n",
    "y_val2 = y_val > 0.\n",
    "\n",
    "score = roc_auc_score(y_val2, y_pred_prob)\n",
    "print(score)\n",
    "target_names = [0, 1]\n",
    "cm = confusion_matrix(y_val2, y_pred, target_names=target_names, normalize='true')\n",
    "cr = classification_report(y_val2, y_pred, target_names=target_names)\n",
    "print(cm)\n",
    "print(cr)\n",
    "\n",
    "# return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG dist\n",
    "hist_kwargs = dict(lw=2, alpha=0.75, histtype=\"step\", bins=26, range=(-2,2))\n",
    "plt.hist(y_pred_prob, label='prob', **hist_kwargs, )\n",
    "plt.hist(y_val2,label='pred',  **hist_kwargs,)\n",
    "plt.hist(y_pred, label='truth',  **hist_kwargs,)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.hist(y_pred_raw, label='pred',  **hist_kwargs,)\n",
    "plt.hist(y_val,  label='truth',  **hist_kwargs,)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv direct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional import accuracy, auroc, f1_score, jaccard_index, dice\n",
    "from src.models.pl_ranking_probe import LinBnDrop, InceptionBlock, PLRankingBase\n",
    "\n",
    "class PLConvProbeLinearCls(PLRankingBase):\n",
    "\n",
    "    def __init__(self, c_in, total_steps, depth=0, lr=4e-3, weight_decay=1e-9, hs=8, dropout=0, **kwargs):\n",
    "        super().__init__(total_steps=total_steps, lr=lr, weight_decay=weight_decay)\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        \n",
    "        self.pre = nn.Sequential(\n",
    "            # nn.BatchNorm2d(c_in[1], affine=False),\n",
    "            nn.Conv2d(c_in[1], hs*4, (1, 2)),\n",
    "            nn.Conv2d(hs*4, hs*4, (2, 1)),\n",
    "        )\n",
    "\n",
    "        layers = [\n",
    "            nn.BatchNorm1d(hs*4, affine=False)\n",
    "            ]\n",
    "        for i in range(depth+1):\n",
    "            if (i>0) and (i<depth):\n",
    "                layers.append(InceptionBlock(hs*4, hs, conv_dropout=dropout))\n",
    "            elif i==0: # first layer\n",
    "                if depth==0: \n",
    "                    layers.append(InceptionBlock(hs*4, 1))\n",
    "                else:\n",
    "                    layers.append(InceptionBlock(hs*4, hs, conv_dropout=dropout))\n",
    "            else: # last layer\n",
    "                layers.append(nn.Conv1d(hs*4, 1, 1))\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "        \n",
    "        n = c_in[0] - 1\n",
    "        self.head = nn.Sequential(\n",
    "            LinBnDrop(n, n, p=dropout),\n",
    "            LinBnDrop(n, n, p=dropout),\n",
    "            nn.Linear(n, 1),  \n",
    "            # nn.Tanh(), \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if x.ndim==4:\n",
    "            x = x.squeeze(3)\n",
    "        x = rearrange(x, 'b l h n -> b h l n')\n",
    "        x = self.pre(x)\n",
    "        x = rearrange(x, 'b h l n -> b h (l n)')\n",
    "        x = self.conv(x)\n",
    "        x = rearrange(x, 'b l h -> b (l h)')\n",
    "        return self.head(x).squeeze(1)\n",
    "    \n",
    "    def _step(self, batch, batch_idx, stage='train'):\n",
    "        x0, y = batch\n",
    "        logits = self(x0)\n",
    "        ypred = torch.sigmoid(logits)\n",
    "        \n",
    "        if stage=='pred':\n",
    "            return ypred.float()\n",
    "        \n",
    "        loss = F.binary_cross_entropy_with_logits(logits, y.float())\n",
    "        \n",
    "        self.log(f\"{stage}/acc\", accuracy(ypred, y, \"binary\"), on_epoch=True, on_step=False)\n",
    "        self.log(f\"{stage}/loss\", loss, on_epoch=True, on_step=False)\n",
    "        self.log(f\"{stage}/n\", len(y), on_epoch=True, on_step=False, reduce_fx=torch.sum)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = ranking_truth_telling(ds_out)\n",
    "X = torch.stack([hs_normal,hs_intervene], 3)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "to_ds = lambda hs, y: TensorDataset(hs, y)\n",
    "dl_train = DataLoader(to_ds(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "dl_val = DataLoader(to_ds(X_val, y_val), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "x1,y1 = next(iter(dl_train))\n",
    "c_in = x1.shape[1:]\n",
    "print(c_in)\n",
    "net = PLConvProbeLinearCls(c_in, total_steps=max_epochs * len(dl_train), depth=2, lr=4e-3, weight_decay=1e-5, hs=16, dropout=0.2)\n",
    "# print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "summary(net, input_data=x1) # input_size=(batch_size, 1, 28, 28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(c_in)\n",
    "# with torch.no_grad():\n",
    "#     net(x1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "trainer1 = pl.Trainer(\n",
    "    gradient_clip_val=20,\n",
    "    # accelerator=\"auto\",\n",
    "    # devices=\"1\",\n",
    "    max_epochs=max_epochs,\n",
    "    log_every_n_steps=1,\n",
    "    enable_progress_bar=verbose, enable_model_summary=verbose\n",
    ")\n",
    "trainer1.fit(model=net, train_dataloaders=dl_train, val_dataloaders=dl_val);\n",
    "\n",
    "\n",
    "\n",
    "df_hist, df_hist_step  = read_metrics_csv(trainer1.logger.experiment.metrics_file_path)\n",
    "\n",
    "df_hist[['val/acc', 'train/acc']].plot()\n",
    "# df_hist[['val/loss', 'train/loss']].plot()\n",
    "# df_hist_step[['val/acc', 'train/acc']].plot(style=\".\")\n",
    "# df_hist_step[['val/loss', 'train/loss']].plot(style=\".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = trainer1.predict(net, dataloaders=dl_val)\n",
    "y_pred_prob = torch.cat(r).flatten()\n",
    "y_pred = y_pred_prob > 0.5\n",
    "\n",
    "score = roc_auc_score(y_val, y_pred_prob)\n",
    "\n",
    "print(score)\n",
    "target_names = [0, 1]\n",
    "cm = confusion_matrix(y_val, y_pred, target_names=target_names, normalize='true')\n",
    "cr = classification_report(y_val, y_pred, target_names=target_names)\n",
    "print(cm)\n",
    "print(cr)\n",
    "\n",
    "# return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DEBUG DIST\n",
    "# hist_kwargs = dict(lw=2, alpha=0.75, histtype=\"step\", bins=26, range=(-2,2))\n",
    "# plt.hist(y_pred_prob, label='prob', **hist_kwargs, )\n",
    "# plt.hist(y_val2,label='pred',  **hist_kwargs,)\n",
    "# plt.hist(y_pred, label='truth',  **hist_kwargs,)\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# plt.hist(y_pred_raw, label='pred',  **hist_kwargs,)\n",
    "# plt.hist(y_val,  label='truth',  **hist_kwargs,)\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPYTORCH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "from src.probes.gp import GPClassificationModel\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from src.helpers.pandas_classification_report import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "from src.eval.interventions import preproc, prostproc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # label_fn = ds2label_model_truth\n",
    "# y = ranking_truth_telling(ds_out)>0\n",
    "# # hs = torch.stack([hs_normal,hs_intervene], 3)\n",
    "# hs = hs_normal - hs_intervene\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dl_train = DataLoader(TensorDataset(X_train, y_train), batch_size=256, shuffle=True)\n",
    "# dl_val = DataLoader(TensorDataset(X_val, y_val), batch_size=256, shuffle=False)\n",
    "# max_epochs = 50\n",
    "\n",
    "# pl_gp = PLGP(epoch_steps=len(X_train), max_epochs=max_epochs, lr=4e-3, weight_decay=0)\n",
    "# trainer = pl.Trainer(\n",
    "#     gradient_clip_val=20,\n",
    "#     accelerator=\"auto\",\n",
    "#     # devices=\"1\",\n",
    "#     max_epochs=max_epochs,\n",
    "#     log_every_n_steps=1,\n",
    "#     # enable_progress_bar=verbose, enable_model_summary=verbose\n",
    "# )\n",
    "\n",
    "# trainer.fit(model=pl_gp, train_dataloaders=dl_train, val_dataloaders=dl_val);\n",
    "# df_hist, _ = read_metrics_csv(trainer.logger.experiment.metrics_file_path)\n",
    "# df_hist[['val/loss_epoch', 'train/loss_epoch']].plot()\n",
    "# df_hist[['val/acc', 'train/acc']].plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantile"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
