{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This nb is to prototype and compare probes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "from typing import Optional, List, Dict, Union\n",
    "from jaxtyping import Float\n",
    "from torch import Tensor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import Tensor\n",
    "from torch import optim\n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset\n",
    "\n",
    "from pathlib import Path\n",
    "from einops import rearrange\n",
    "\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "logger.add(os.sys.stderr, format=\"{time} {level} {message}\", level=\"INFO\")\n",
    "\n",
    "# # quiet please\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load my code\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from src.datasets.dm import DeceptionDataModule\n",
    "from src.models.pl_lora_ft import AtapterFinetuner\n",
    "\n",
    "from src.config import ExtractConfig\n",
    "from src.prompts.prompt_loading import load_preproc_dataset, load_preproc_datasets\n",
    "from src.models.load import load_model\n",
    "from src.helpers.torch_helpers import clear_mem\n",
    "from src.models.phi.model_phi import PhiForCausalLMWHS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load previously made datasets of hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1.3G\n",
      "drwxrwxr-x 9 wassname wassname 4.0K Dec 23 18:17 ..\n",
      "-rw-rw-r-- 1 wassname wassname 209M Dec 23 18:51 ds_OOD_6e05f2126512ce02\n",
      "-rw-rw-r-- 1 wassname wassname 209M Dec 23 18:54 ds_valtest_a295cab1f3d786a1\n",
      "-rw-rw-r-- 1 wassname wassname 209M Dec 24 06:45 ds_OOD_89ad9d7b591f3c44\n",
      "-rw-rw-r-- 1 wassname wassname 209M Dec 24 06:49 ds_valtest_7777409fa7e08370\n",
      "-rw-rw-r-- 1 wassname wassname 209M Dec 24 07:45 ds_OOD_88214ab52bf8f023\n",
      "drwxrwxr-x 2 wassname wassname 4.0K Dec 24 07:45 .\n",
      "-rw-rw-r-- 1 wassname wassname 209M Dec 24 07:49 ds_valtest_8c031b4aa03ae4d2\n",
      "-rw-rw-r-- 1 wassname wassname 209M Dec 24 07:49 /media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/.ds/ds_valtest_8c031b4aa03ae4d2\n"
     ]
    }
   ],
   "source": [
    "!ls -altrh '/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/.ds/'\n",
    "\n",
    "!ls -altrh '/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/.ds/ds_valtest_8c031b4aa03ae4d2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_ood = '/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/.ds/ds_OOD_88214ab52bf8f023'\n",
    "f1_val = '/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/.ds/ds_valtest_8c031b4aa03ae4d2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['end_logits_base', 'choice_probs_base', 'binary_ans_base', 'label_true_base', 'label_instructed_base', 'instructed_to_lie_base', 'sys_instr_name_base', 'example_i_base', 'ds_string_base', 'template_name_base', 'correct_truth_telling_base', 'correct_instruction_following_base', 'end_residual_stream_base', 'end_logits_adapt', 'choice_probs_adapt', 'binary_ans_adapt', 'label_true_adapt', 'label_instructed_adapt', 'instructed_to_lie_adapt', 'sys_instr_name_adapt', 'example_i_adapt', 'ds_string_adapt', 'template_name_adapt', 'correct_truth_telling_adapt', 'correct_instruction_following_adapt', 'end_residual_stream_adapt'],\n",
       "    num_rows: 201\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_val = Dataset.from_file(f1_val).with_format(\"torch\")\n",
    "\n",
    "ds_oos = Dataset.from_file(f1_ood).with_format(\"torch\")\n",
    "ds_out = ds_oos\n",
    "ds_oos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probes\n",
    "\n",
    "## Linear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select rows are 45.83% based on knowledge\n",
      "          0         1\n",
      "0  0.724138  0.275862\n",
      "1  0.279070  0.720930\n",
      "              precision  recall  f1-score  support\n",
      "0                  0.78    0.72      0.75       58\n",
      "1                  0.66    0.72      0.69       43\n",
      "accuracy           0.72    0.72      0.72      101\n",
      "macro avg          0.72    0.72      0.72      101\n",
      "weighted avg       0.73    0.72      0.72      101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7538091419406575"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.eval.interventions import check_lr_intervention_predictive\n",
    "from src.eval.labels import ranking_truth_telling\n",
    "from src.eval.ds import filter_ds_to_known\n",
    "ds_known = filter_ds_to_known(ds_out, verbose=True)\n",
    "hs_normal = ds_out['end_residual_stream_base']\n",
    "hs_intervene = ds_out['end_residual_stream_adapt']\n",
    "label_fn = ranking_truth_telling\n",
    "hs = hs_normal - hs_intervene\n",
    "y = label_fn(ds_out)\n",
    "\n",
    "\n",
    "check_lr_intervention_predictive(hs, y, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantile"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
