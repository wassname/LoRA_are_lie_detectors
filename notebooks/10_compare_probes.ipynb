{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we try a variety of probes\n",
    "\n",
    "They all fit into a sklearn style api, except they take torch tensors of >2 dims\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TQDM_DISABLE'] = '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "from typing import Optional, List, Dict, Union\n",
    "from jaxtyping import Float\n",
    "from torch import Tensor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import Tensor\n",
    "from torch import optim\n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset\n",
    "\n",
    "from pathlib import Path\n",
    "from einops import rearrange\n",
    "\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "\n",
    "from typing import Optional, List, Dict, Union, Tuple\n",
    "from jaxtyping import Float\n",
    "from torch import Tensor\n",
    "\n",
    "logger.add(os.sys.stderr, format=\"{time} {level} {message}\", level=\"INFO\")\n",
    "\n",
    "# # quiet please\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# load my code\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from src.datasets.dm import DeceptionDataModule\n",
    "from src.models.pl_lora_ft import AtapterFinetuner\n",
    "\n",
    "from src.config import ExtractConfig\n",
    "from src.prompts.prompt_loading import load_preproc_dataset, load_preproc_datasets\n",
    "from src.models.load import load_model\n",
    "from src.helpers.torch_helpers import clear_mem\n",
    "from src.models.phi.model_phi import PhiForCausalLMWHS\n",
    "# from src.eval.interventions import check_lr_intervention_predictive\n",
    "from src.probes.utils import postproc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# plt.style.use(\"ggplot\")\n",
    "\n",
    "plt.style.use(['seaborn-v0_8', 'seaborn-v0_8-paper'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.eval.labels import ranking_truth_telling, ds2label_model_truth\n",
    "from src.eval.ds import filter_ds_to_known\n",
    "\n",
    "from src.probes.pl_ranking_probe import PLConvProbeLinear\n",
    "from src.helpers.lightning import read_metrics_csv\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from src.helpers.pandas_classification_report import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from functools import partial\n",
    "from src.eval.labels import ranking_truth_telling, undo_ranked_truth_telling\n",
    "from src.helpers.ds import train_test_split_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "?# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 20\n",
    "batch_size=16\n",
    "verbose = False\n",
    "MAX_SAMPLES = 600\n",
    "SKIP=5\n",
    "STIDE=2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load data, previously collected, from the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls -altrh '/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/.ds/'\n",
    "# # !ls -altrh '/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/.ds/ds_valtest_8c031b4aa03ae4d2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/.venv/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select rows are 76.89% based on knowledge\n"
     ]
    }
   ],
   "source": [
    "# load hidden state from a previously loaded adapter\n",
    "# the columns with _base are from the base model, and adapt from adapter\n",
    "f1_ood = '/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/.ds/ds_OOD_6d3ece46c44f6c3b'\n",
    "f1_val = '/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/.ds/ds_valtest_73b754e8fdff9f2f'\n",
    "ds_val = Dataset.from_file(f1_val).with_format(\"torch\")\n",
    "ds_oos = Dataset.from_file(f1_ood).with_format(\"torch\")\n",
    "\n",
    "ds_out = datasets.interleave_datasets([ds_val, ds_oos], seed=42, \n",
    "                                    #   probabilities=[0.5, 0.5]\n",
    "                                      )\n",
    "ds_known1 = filter_ds_to_known(ds_out, verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['end_logits_base', 'choice_probs_base', 'binary_ans_base', 'label_true_base', 'label_instructed_base', 'instructed_to_lie_base', 'sys_instr_name_base', 'example_i_base', 'ds_string_base', 'template_name_base', 'correct_truth_telling_base', 'correct_instruction_following_base', 'end_residual_stream_base', 'end_logits_adapt', 'choice_probs_adapt', 'binary_ans_adapt', 'label_true_adapt', 'label_instructed_adapt', 'instructed_to_lie_adapt', 'sys_instr_name_adapt', 'example_i_adapt', 'ds_string_adapt', 'template_name_adapt', 'correct_truth_telling_adapt', 'correct_instruction_following_adapt', 'end_residual_stream_adapt', 'end_logits_adapt2', 'choice_probs_adapt2', 'binary_ans_adapt2', 'label_true_adapt2', 'label_instructed_adapt2', 'instructed_to_lie_adapt2', 'sys_instr_name_adapt2', 'example_i_adapt2', 'ds_string_adapt2', 'template_name_adapt2', 'correct_truth_telling_adapt2', 'correct_instruction_following_adapt2', 'end_residual_stream_adapt2', 'end_logits_base2', 'choice_probs_base2', 'binary_ans_base2', 'label_true_base2', 'label_instructed_base2', 'instructed_to_lie_base2', 'sys_instr_name_base2', 'example_i_base2', 'ds_string_base2', 'template_name_base2', 'correct_truth_telling_base2', 'correct_instruction_following_base2', 'end_residual_stream_base2'],\n",
       "    num_rows: 2140\n",
       "})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flip_even_rows(row: dict, idx: int) -> dict:\n",
    "    \"\"\"this will flip adapter and base keys for even rows, this balances the task.\"\"\"\n",
    "    # also record the original rows, and which ones are flipped?\n",
    "    row2 = {k.replace('_base', '_base2').replace('_adapt', '_adapt2'): v for k, v in row.items()}\n",
    "    row = {**row2, **row}\n",
    "    \n",
    "    if idx%2 == 0:\n",
    "        row = {k.replace('_base', '_tmp'): v for k, v in row.items()}\n",
    "        row = {k.replace('_adapt', '_base'): v for k, v in row.items()} \n",
    "        row = {k.replace('_tmp', '_adapt'): v for k, v in row.items()}\n",
    "    return row\n",
    "\n",
    "ds_known = ds_known1.map(flip_even_rows, with_indices=True)\n",
    "ds_known\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split datasets\n",
    "\n",
    "we want to split by insample (from training) and out of distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(amazon_polarity    267\n",
       " glue:qnli          267\n",
       " super_glue:rte     267\n",
       " super_glue:axg     267\n",
       " sst2               267\n",
       " hans               267\n",
       " Name: count, dtype: int64,\n",
       " super_glue:boolq    534\n",
       " super_glue:axg      534\n",
       " imdb                534\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(amazon_polarity    267\n",
       " glue:qnli          267\n",
       " super_glue:rte     267\n",
       " super_glue:axg     267\n",
       " sst2               267\n",
       " hans               267\n",
       " Name: count, dtype: int64,\n",
       " super_glue:boolq    534\n",
       " super_glue:axg      534\n",
       " imdb                534\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(ds_val['ds_string_base']).value_counts(), pd.Series(ds_oos['ds_string_base']).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sst2', 'hans', 'super_glue:axg', 'glue:qnli', 'amazon_polarity', 'super_glue:rte'] ['imdb', 'super_glue:axg', 'super_glue:boolq']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['sst2',\n",
       "  'hans',\n",
       "  'super_glue:axg',\n",
       "  'glue:qnli',\n",
       "  'amazon_polarity',\n",
       "  'super_glue:rte',\n",
       "  'imdb'],\n",
       " ['super_glue:axg', 'super_glue:boolq'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_datasets = list(set(ds_val['ds_string_base']))\n",
    "outsample_datasets = list(set(ds_oos['ds_string_base']))\n",
    "print(insample_datasets, outsample_datasets)\n",
    "\n",
    "trainval_datasets = insample_datasets + outsample_datasets[:1]\n",
    "test_datasets = outsample_datasets[1:]\n",
    "trainval_datasets, test_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sst2', 'hans', 'super_glue:axg', 'glue:qnli', 'amazon_polarity', 'super_glue:rte'] ['imdb', 'super_glue:axg', 'super_glue:boolq']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['super_glue:rte',\n",
       "  'amazon_polarity',\n",
       "  'hans',\n",
       "  'glue:qnli',\n",
       "  'super_glue:axg',\n",
       "  'sst2'],\n",
       " ['super_glue:boolq', 'imdb'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIXME: DELETEME: ONCE I HAVE RERUN BASE MODEL\n",
    "\n",
    "insample_datasets = list(set(ds_val['ds_string_base']))\n",
    "outsample_datasets = list(set(ds_oos['ds_string_base']))\n",
    "print(insample_datasets, outsample_datasets)\n",
    "\n",
    "trainval_datasets = ['super_glue:rte', 'amazon_polarity', 'hans', 'glue:qnli', 'super_glue:axg', 'sst2']\n",
    "test_datasets = ['super_glue:boolq', 'imdb']\n",
    "trainval_datasets, test_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 600)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_trainval = ds_known.filter(lambda example: example[\"ds_string_base\"] in trainval_datasets)\n",
    "ds_test = ds_known.filter(lambda example: example[\"ds_string_base\"] not in trainval_datasets)\n",
    "\n",
    "MAX_SAMPLES = min(len(ds_known), MAX_SAMPLES)\n",
    "ds_trainval = ds_trainval.select(range(MAX_SAMPLES))\n",
    "\n",
    "MAX_SAMPLES = min(len(ds_test), MAX_SAMPLES)\n",
    "ds_test = ds_test.select(range(MAX_SAMPLES))\n",
    "\n",
    "\n",
    "len(ds_trainval), len(ds_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ds_train, ds_val = train_test_split_ds(ds_trainval, test_size=0.3, stratify_columns=['ds_string_base'])\n",
    "# len(ds_train), len(ds_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set labels\n",
    "ds2proxy = ranking_truth_telling\n",
    "proxy2label = undo_ranked_truth_telling\n",
    "\n",
    "# unit test labels\n",
    "y_val1 = ds2proxy(ds_val)\n",
    "y1 = proxy2label(y_val1, ds_val)\n",
    "np.testing.assert_array_equal(y1, ds_val['label_true_base'], err_msg=\"undo_distance_truth_telling failed\")\n",
    "# assert (y1 == ds_val['label_true_base']).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "class TorchRobustScaler(RobustScaler):\n",
    "\n",
    "    def wrap(self, X, method: str):\n",
    "        b, l, h, v = X.shape\n",
    "        X = rearrange(X, \"b l h v -> b (l h v)\")\n",
    "        X = getattr(super(), method)(X)\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = torch.from_numpy(rearrange(X, \"b (l h v) -> b l h v\", l=l, h=h, v=v))\n",
    "        return X\n",
    "\n",
    "    def fit(self, X):\n",
    "        return self.wrap(X, \"fit\")\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.wrap(X, \"transform\")\n",
    "\n",
    "    def inverse_transform(self, X):\n",
    "        return self.wrap(X, \"inverse_transform\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([600, 14, 2559, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds_trainval\n",
    "x = torch.stack([ds['end_residual_stream_base'], ds['end_residual_stream_adapt']], -1)[:, SKIP::STIDE]\n",
    "y = ds2proxy(ds)\n",
    "x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.eval.ds import ds2df\n",
    "\n",
    "\n",
    "\n",
    "def ds2dfres(model, scaler, ds_test, verbose=True):\n",
    "    \"\"\"dataset to dataframe with predictions\"\"\"\n",
    "    X_test, y_test_proxy = ds2xy(ds_test)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    y_test_proxy_prob = model.predict_proba(X_test)\n",
    "    y_test = proxy2label(y_test_proxy, ds_test)\n",
    "    y_test_prob = proxy2label(y_test_proxy_prob, ds_test)\n",
    "    df_test = ds2df(ds_test)\n",
    "    df_test['y_prob'] = y_test_prob\n",
    "    df_test['y'] = y_test > 0.5\n",
    "    df_test['y_proxy_prob'] = y_test_prob\n",
    "    df_test['y_test_proxy'] = y_test_proxy\n",
    "    if verbose:\n",
    "        postproc(y_test_prob, y_test, verbose=verbose)\n",
    "    return df_test\n",
    "\n",
    "def ds2xy(ds: Dataset) -> Tuple[Tensor, Tensor]:\n",
    "    x = torch.stack([ds['end_residual_stream_base'], ds['end_residual_stream_adapt']], -1)[:, SKIP::STIDE]\n",
    "    y = ds2proxy(ds)\n",
    "    return x, y\n",
    "\n",
    "def eval_ranking(model, ds_trainval: Dataset, ds_test: Dataset):\n",
    "    \"\"\"Evaluate a scikit learn style model, with a ranking proxy label.\"\"\"\n",
    "\n",
    "    # split\n",
    "    ds_train, ds_val = train_test_split_ds(ds_trainval, test_size=0.3)\n",
    "    X_val, y_val_proxy = ds2xy(ds_val)\n",
    "    X_train, y_train_proxy = ds2xy(ds_train)\n",
    "    X_test, y_test = ds2xy(ds_test)\n",
    "\n",
    "    # scale\n",
    "    scaler = TorchRobustScaler(with_centering=False, with_scaling=True)\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    model.fit(X_train=X_train, y_train=y_train_proxy, X_val=X_val, y_val=y_val_proxy)\n",
    "\n",
    "    # must return a single torch float probability\n",
    "    y_val_proxy_prob = model.predict_proba(X_val)\n",
    "    assert y_val_proxy_prob.max()<=1\n",
    "    assert y_val_proxy_prob.min()>=0\n",
    "    assert y_val_proxy_prob.ndim == 1, \"model must return a single probability\"\n",
    "    assert y_val_proxy_prob.shape[0] == X_val.shape[0], \"model must return a single probability for each sample\"\n",
    "    assert isinstance(y_val_proxy_prob, torch.Tensor), \"model must return a torch tensor\"\n",
    "    assert torch.is_floating_point(y_val_proxy_prob), \"model must return a torch tensor\"\n",
    "\n",
    "    df_res1 = ds2dfres(model, scaler, ds_val, False)\n",
    "    df_res2 = ds2dfres(model, scaler, ds_test, False)\n",
    "    df_res = pd.concat([df_res1, df_res2])\n",
    "    return df_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dfres(df_res):\n",
    "    data = {}\n",
    "    for n, g in df_res.groupby('ds_string_base'):\n",
    "        roc_auc = roc_auc_score(g['y'], g['y_prob'])\n",
    "        acc = accuracy_score(g['y'], g['y_prob']>0.5)\n",
    "        in_adapter_distribution = n in insample_datasets\n",
    "        in_train = n in trainval_datasets\n",
    "\n",
    "\n",
    "        roc_auc_adapter = roc_auc_score(g['label_true_adapt2'], g['binary_ans_adapt2'])\n",
    "        roc_auc_base = roc_auc_score(g['label_true_base2'], g['binary_ans_base2'])\n",
    "\n",
    "\n",
    "        s= pd.Series(dict(\n",
    "            roc_auc=roc_auc,\n",
    "            improvement=roc_auc-max(roc_auc_adapter, roc_auc_base),\n",
    "            acc=acc,\n",
    "            n=len(g),\n",
    "            in_dist_adapter=in_adapter_distribution,\n",
    "            in_dist_probe=in_train,\n",
    "            balance=g['y'].mean(),\n",
    "            balance_proxy=g['y_test_proxy'].mean(),\n",
    "            roc_auc_adapter=roc_auc_adapter,\n",
    "            roc_auc_base=roc_auc_base,\n",
    "\n",
    "            # baseline=g['y_proxy_prob'].mean(),\n",
    "        ))\n",
    "        # print(s)\n",
    "        data[n]=s\n",
    "\n",
    "    df = pd.DataFrame(data).T.sort_values('improvement', ascending=False)\n",
    "    # df['better'] = df['roc_auc']-df[['roc_auc_adapter', 'roc_auc_base']].values.max(1)\n",
    "    display(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from einops import rearrange\n",
    "\n",
    "class TorchLogisticRegression(LogisticRegression):\n",
    "\n",
    "    def fit(self, X_train, y_train, sample_weight = None, **kwargs):\n",
    "        X_train = rearrange(X_train, 'b l h v -> b (l h v)')\n",
    "        return super().fit(X_train.numpy(), y_train.numpy(), sample_weight)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X = rearrange(X, 'b l h v -> b (l h v)').numpy()\n",
    "        return torch.from_numpy(super().predict_proba(X)[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>improvement</th>\n",
       "      <th>acc</th>\n",
       "      <th>n</th>\n",
       "      <th>in_dist_adapter</th>\n",
       "      <th>in_dist_probe</th>\n",
       "      <th>balance</th>\n",
       "      <th>balance_proxy</th>\n",
       "      <th>roc_auc_adapter</th>\n",
       "      <th>roc_auc_base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>glue:qnli</th>\n",
       "      <td>0.85625</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.6375</td>\n",
       "      <td>0.66875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sst2</th>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.896825</td>\n",
       "      <td>0.865079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>super_glue:axg</th>\n",
       "      <td>0.997685</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.97619</td>\n",
       "      <td>42</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.52381</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.976852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imdb</th>\n",
       "      <td>0.944318</td>\n",
       "      <td>-0.002652</td>\n",
       "      <td>0.904255</td>\n",
       "      <td>282</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.492908</td>\n",
       "      <td>0.94697</td>\n",
       "      <td>0.945455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>super_glue:rte</th>\n",
       "      <td>0.805128</td>\n",
       "      <td>-0.005128</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>28</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.810256</td>\n",
       "      <td>0.789744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hans</th>\n",
       "      <td>0.684524</td>\n",
       "      <td>-0.005952</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.577381</td>\n",
       "      <td>0.690476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amazon_polarity</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>-0.046667</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>35</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>super_glue:boolq</th>\n",
       "      <td>0.862177</td>\n",
       "      <td>-0.099196</td>\n",
       "      <td>0.795597</td>\n",
       "      <td>318</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.459119</td>\n",
       "      <td>0.449686</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.935808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   roc_auc improvement       acc    n in_dist_adapter  \\\n",
       "glue:qnli          0.85625      0.1875  0.730769   26            True   \n",
       "sst2              0.968254    0.071429  0.869565   23            True   \n",
       "super_glue:axg    0.997685    0.020833   0.97619   42            True   \n",
       "imdb              0.944318   -0.002652  0.904255  282           False   \n",
       "super_glue:rte    0.805128   -0.005128  0.785714   28            True   \n",
       "hans              0.684524   -0.005952  0.615385   26            True   \n",
       "amazon_polarity   0.933333   -0.046667  0.914286   35            True   \n",
       "super_glue:boolq  0.862177   -0.099196  0.795597  318           False   \n",
       "\n",
       "                 in_dist_probe   balance balance_proxy roc_auc_adapter  \\\n",
       "glue:qnli                 True  0.384615      0.538462          0.6375   \n",
       "sst2                      True  0.608696      0.521739        0.896825   \n",
       "super_glue:axg            True  0.428571       0.52381        0.898148   \n",
       "imdb                     False  0.531915      0.492908         0.94697   \n",
       "super_glue:rte            True  0.464286      0.535714        0.810256   \n",
       "hans                      True  0.538462      0.576923        0.577381   \n",
       "amazon_polarity           True  0.428571           0.4            0.98   \n",
       "super_glue:boolq         False  0.459119      0.449686        0.961373   \n",
       "\n",
       "                 roc_auc_base  \n",
       "glue:qnli             0.66875  \n",
       "sst2                 0.865079  \n",
       "super_glue:axg       0.976852  \n",
       "imdb                 0.945455  \n",
       "super_glue:rte       0.789744  \n",
       "hans                 0.690476  \n",
       "amazon_polarity          0.92  \n",
       "super_glue:boolq     0.935808  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = TorchLogisticRegression(random_state=42, \n",
    "                                # max_iter=1000,\n",
    "                                 class_weight='balanced',)\n",
    "df_res = eval_ranking(model, ds_trainval, ds_test)\n",
    "df_res2 = analyze_dfres(df_res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline: DummyClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from einops import rearrange\n",
    "\n",
    "class TorchDummyClassifier(DummyClassifier):\n",
    "\n",
    "    def fit(self, X_train, y_train, sample_weight = None, **kwargs):\n",
    "        X_train = rearrange(X_train, 'b l h v -> b (l h v)')\n",
    "        return super().fit(X_train.numpy(), y_train.numpy(), sample_weight)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X = rearrange(X, 'b l h v -> b (l h v)').numpy()\n",
    "        return torch.from_numpy(super().predict_proba(X)[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>improvement</th>\n",
       "      <th>acc</th>\n",
       "      <th>n</th>\n",
       "      <th>in_dist_adapter</th>\n",
       "      <th>in_dist_probe</th>\n",
       "      <th>balance</th>\n",
       "      <th>balance_proxy</th>\n",
       "      <th>roc_auc_adapter</th>\n",
       "      <th>roc_auc_base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>glue:qnli</th>\n",
       "      <td>0.60625</td>\n",
       "      <td>-0.0625</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.6375</td>\n",
       "      <td>0.66875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hans</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>-0.119048</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.577381</td>\n",
       "      <td>0.690476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>super_glue:rte</th>\n",
       "      <td>0.535897</td>\n",
       "      <td>-0.274359</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>28</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.810256</td>\n",
       "      <td>0.789744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sst2</th>\n",
       "      <td>0.527778</td>\n",
       "      <td>-0.369048</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.896825</td>\n",
       "      <td>0.865079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>super_glue:axg</th>\n",
       "      <td>0.534722</td>\n",
       "      <td>-0.44213</td>\n",
       "      <td>0.52381</td>\n",
       "      <td>42</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.52381</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.976852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imdb</th>\n",
       "      <td>0.49197</td>\n",
       "      <td>-0.455</td>\n",
       "      <td>0.492908</td>\n",
       "      <td>282</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.492908</td>\n",
       "      <td>0.94697</td>\n",
       "      <td>0.945455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>super_glue:boolq</th>\n",
       "      <td>0.446241</td>\n",
       "      <td>-0.515132</td>\n",
       "      <td>0.449686</td>\n",
       "      <td>318</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.459119</td>\n",
       "      <td>0.449686</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.935808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amazon_polarity</th>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.4</td>\n",
       "      <td>35</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   roc_auc improvement       acc    n in_dist_adapter  \\\n",
       "glue:qnli          0.60625     -0.0625  0.538462   26            True   \n",
       "hans              0.571429   -0.119048  0.576923   26            True   \n",
       "super_glue:rte    0.535897   -0.274359  0.535714   28            True   \n",
       "sst2              0.527778   -0.369048  0.521739   23            True   \n",
       "super_glue:axg    0.534722    -0.44213   0.52381   42            True   \n",
       "imdb               0.49197      -0.455  0.492908  282           False   \n",
       "super_glue:boolq  0.446241   -0.515132  0.449686  318           False   \n",
       "amazon_polarity        0.4       -0.58       0.4   35            True   \n",
       "\n",
       "                 in_dist_probe   balance balance_proxy roc_auc_adapter  \\\n",
       "glue:qnli                 True  0.384615      0.538462          0.6375   \n",
       "hans                      True  0.538462      0.576923        0.577381   \n",
       "super_glue:rte            True  0.464286      0.535714        0.810256   \n",
       "sst2                      True  0.608696      0.521739        0.896825   \n",
       "super_glue:axg            True  0.428571       0.52381        0.898148   \n",
       "imdb                     False  0.531915      0.492908         0.94697   \n",
       "super_glue:boolq         False  0.459119      0.449686        0.961373   \n",
       "amazon_polarity           True  0.428571           0.4            0.98   \n",
       "\n",
       "                 roc_auc_base  \n",
       "glue:qnli             0.66875  \n",
       "hans                 0.690476  \n",
       "super_glue:rte       0.789744  \n",
       "sst2                 0.865079  \n",
       "super_glue:axg       0.976852  \n",
       "imdb                 0.945455  \n",
       "super_glue:boolq     0.935808  \n",
       "amazon_polarity          0.92  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>improvement</th>\n",
       "      <th>acc</th>\n",
       "      <th>n</th>\n",
       "      <th>in_dist_adapter</th>\n",
       "      <th>in_dist_probe</th>\n",
       "      <th>balance</th>\n",
       "      <th>balance_proxy</th>\n",
       "      <th>roc_auc_adapter</th>\n",
       "      <th>roc_auc_base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>glue:qnli</th>\n",
       "      <td>0.60625</td>\n",
       "      <td>-0.0625</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.6375</td>\n",
       "      <td>0.66875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hans</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>-0.119048</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.577381</td>\n",
       "      <td>0.690476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>super_glue:rte</th>\n",
       "      <td>0.535897</td>\n",
       "      <td>-0.274359</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>28</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.810256</td>\n",
       "      <td>0.789744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sst2</th>\n",
       "      <td>0.527778</td>\n",
       "      <td>-0.369048</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.896825</td>\n",
       "      <td>0.865079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>super_glue:axg</th>\n",
       "      <td>0.534722</td>\n",
       "      <td>-0.44213</td>\n",
       "      <td>0.52381</td>\n",
       "      <td>42</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.52381</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.976852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imdb</th>\n",
       "      <td>0.49197</td>\n",
       "      <td>-0.455</td>\n",
       "      <td>0.492908</td>\n",
       "      <td>282</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.492908</td>\n",
       "      <td>0.94697</td>\n",
       "      <td>0.945455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>super_glue:boolq</th>\n",
       "      <td>0.446241</td>\n",
       "      <td>-0.515132</td>\n",
       "      <td>0.449686</td>\n",
       "      <td>318</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.459119</td>\n",
       "      <td>0.449686</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.935808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amazon_polarity</th>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.4</td>\n",
       "      <td>35</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   roc_auc improvement       acc    n in_dist_adapter  \\\n",
       "glue:qnli          0.60625     -0.0625  0.538462   26            True   \n",
       "hans              0.571429   -0.119048  0.576923   26            True   \n",
       "super_glue:rte    0.535897   -0.274359  0.535714   28            True   \n",
       "sst2              0.527778   -0.369048  0.521739   23            True   \n",
       "super_glue:axg    0.534722    -0.44213   0.52381   42            True   \n",
       "imdb               0.49197      -0.455  0.492908  282           False   \n",
       "super_glue:boolq  0.446241   -0.515132  0.449686  318           False   \n",
       "amazon_polarity        0.4       -0.58       0.4   35            True   \n",
       "\n",
       "                 in_dist_probe   balance balance_proxy roc_auc_adapter  \\\n",
       "glue:qnli                 True  0.384615      0.538462          0.6375   \n",
       "hans                      True  0.538462      0.576923        0.577381   \n",
       "super_glue:rte            True  0.464286      0.535714        0.810256   \n",
       "sst2                      True  0.608696      0.521739        0.896825   \n",
       "super_glue:axg            True  0.428571       0.52381        0.898148   \n",
       "imdb                     False  0.531915      0.492908         0.94697   \n",
       "super_glue:boolq         False  0.459119      0.449686        0.961373   \n",
       "amazon_polarity           True  0.428571           0.4            0.98   \n",
       "\n",
       "                 roc_auc_base  \n",
       "glue:qnli             0.66875  \n",
       "hans                 0.690476  \n",
       "super_glue:rte       0.789744  \n",
       "sst2                 0.865079  \n",
       "super_glue:axg       0.976852  \n",
       "imdb                 0.945455  \n",
       "super_glue:boolq     0.935808  \n",
       "amazon_polarity          0.92  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TorchDummyClassifier(random_state=42, strategy=\"most_frequent\")\n",
    "df_res = eval_ranking(model, ds_trainval, ds_test)\n",
    "analyze_dfres(df_res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PL Conv MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def distance_truth_telling(ds):\n",
    "    \"\"\"label whether the adapter or the base model were more truthfull.\"\"\"\n",
    "    # even thought it is a distance, we make it center around 0.5 instead of 0, to be compatible with the other metrics\n",
    "    return ds['correct_truth_telling_base'] - ds['correct_truth_telling_adapt'] + 0.5\n",
    "\n",
    "\n",
    "def undo_distance_truth_telling(base_more_truthful: Float[Tensor, ''], ds: Dataset, ):\n",
    "    #note if we know which model is more truthful, and it's a binary choice, we can take the choice that is in that direction as the truth\n",
    "    base_more_truthful = base_more_truthful - 0.5\n",
    "    base_more_positive = (ds['binary_ans_base'] > ds['binary_ans_adapt']) * 1.0\n",
    "    y = base_more_truthful * base_more_positive + (1-base_more_positive) * (-base_more_truthful)\n",
    "    return y > 0.\n",
    "    # return switch(base_more_positive, base_more_truthful)\n",
    "\n",
    "\n",
    "y = distance_truth_telling(ds_val)\n",
    "y1 = undo_distance_truth_telling(y, ds_val)\n",
    "np.testing.assert_array_equal(y1, ds_val['label_true_base'], err_msg=\"undo_distance_truth_telling failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_val['label_true_base']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2proxy = distance_truth_telling\n",
    "proxy2label = undo_distance_truth_telling\n",
    "\n",
    "# FIXME: the distance is 0.5 thresh but 0. Hmm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.probes.pl_ranking_probe import InceptionBlock, LinBnDrop\n",
    "\n",
    "    \n",
    "\n",
    "class HSModel2d(nn.Module):\n",
    "    def __init__(self, c_in, hs, dropout=0, depth=2):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = [nn.BatchNorm1d(c_in[1], affine=False)]\n",
    "        for i in range(depth+1):\n",
    "            if (i>0) and (i<depth):\n",
    "                layers.append(InceptionBlock(hs*4, hs, conv_dropout=dropout))\n",
    "            elif i==0: # first layer\n",
    "                if depth==0: \n",
    "                    layers.append(InceptionBlock(c_in[1], 1))\n",
    "                else:\n",
    "                    layers.append(InceptionBlock(c_in[1], hs, conv_dropout=dropout))\n",
    "            else: # last layer\n",
    "                layers.append(nn.Conv1d(hs*4, 1, 1))\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "        \n",
    "        n = c_in[0]\n",
    "        self.head = nn.Sequential(\n",
    "            LinBnDrop(n, n, p=dropout),\n",
    "            LinBnDrop(n, n, p=dropout),\n",
    "            nn.Linear(n, 1),  \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        x = rearrange(x, 'b l h -> b h l')\n",
    "        x = self.conv(x)\n",
    "        x = rearrange(x, 'b l h -> b (l h)')\n",
    "        return self.head(x).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.helpers.sklearn_lightning import PLSKWrapper, PLSKBase\n",
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "class PLSK2(PLSKBase):\n",
    "    def __init__(self, c_in, dropout=0, hs=32, depth=2, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.model = HSModel2d(c_in, hs, dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def _step(self, batch, batch_idx, stage='train'):\n",
    "        x, y = batch\n",
    "        x0 = x[..., 0]\n",
    "        x1 = x[..., 1]\n",
    "        ypred0 = self(x0)\n",
    "        ypred1 = self(x1)\n",
    "\n",
    "        y_probs = F.sigmoid(ypred0-ypred1+0.5)\n",
    "        y_cls = y_probs > 0.5\n",
    "        \n",
    "        if stage=='pred':\n",
    "            return y_probs\n",
    "        \n",
    "        loss = F.smooth_l1_loss(ypred0-ypred1, y)\n",
    "        \n",
    "        y_cls = ypred1>ypred0 # switch2bool(ypred1-ypred0)\n",
    "        self.log(f\"{stage}/acc\", accuracy(y_cls, y>0.5, \"binary\"), on_epoch=True, on_step=False)\n",
    "        self.log(f\"{stage}/loss\", loss, on_epoch=True, on_step=True, prog_bar=True)\n",
    "        self.log(f\"{stage}/n\", len(y), on_epoch=True, on_step=False, reduce_fx=torch.sum)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 2559, 2])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train, ds_val = train_test_split_ds(ds_trainval, test_size=0.3)\n",
    "X_val, y_val_proxy = ds2xy(ds_val)\n",
    "c_in = X_val.shape[1:]\n",
    "c_in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>improvement</th>\n",
       "      <th>acc</th>\n",
       "      <th>n</th>\n",
       "      <th>in_dist_adapter</th>\n",
       "      <th>in_dist_probe</th>\n",
       "      <th>balance</th>\n",
       "      <th>balance_proxy</th>\n",
       "      <th>roc_auc_adapter</th>\n",
       "      <th>roc_auc_base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>glue:qnli</th>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.01875</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.477667</td>\n",
       "      <td>0.6375</td>\n",
       "      <td>0.66875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hans</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>-0.119048</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.547046</td>\n",
       "      <td>0.577381</td>\n",
       "      <td>0.690476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>super_glue:rte</th>\n",
       "      <td>0.541026</td>\n",
       "      <td>-0.269231</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>28</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.519561</td>\n",
       "      <td>0.810256</td>\n",
       "      <td>0.789744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sst2</th>\n",
       "      <td>0.527778</td>\n",
       "      <td>-0.369048</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.467699</td>\n",
       "      <td>0.896825</td>\n",
       "      <td>0.865079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>super_glue:axg</th>\n",
       "      <td>0.590278</td>\n",
       "      <td>-0.386574</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>42</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.541212</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.976852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imdb</th>\n",
       "      <td>0.507121</td>\n",
       "      <td>-0.439848</td>\n",
       "      <td>0.507092</td>\n",
       "      <td>282</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.485629</td>\n",
       "      <td>0.94697</td>\n",
       "      <td>0.945455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>super_glue:boolq</th>\n",
       "      <td>0.462329</td>\n",
       "      <td>-0.499044</td>\n",
       "      <td>0.465409</td>\n",
       "      <td>318</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.459119</td>\n",
       "      <td>0.475899</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.935808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amazon_polarity</th>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.4</td>\n",
       "      <td>35</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.461685</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   roc_auc improvement       acc    n in_dist_adapter  \\\n",
       "glue:qnli           0.6875     0.01875  0.615385   26            True   \n",
       "hans              0.571429   -0.119048  0.576923   26            True   \n",
       "super_glue:rte    0.541026   -0.269231  0.535714   28            True   \n",
       "sst2              0.527778   -0.369048  0.521739   23            True   \n",
       "super_glue:axg    0.590278   -0.386574  0.571429   42            True   \n",
       "imdb              0.507121   -0.439848  0.507092  282           False   \n",
       "super_glue:boolq  0.462329   -0.499044  0.465409  318           False   \n",
       "amazon_polarity        0.4       -0.58       0.4   35            True   \n",
       "\n",
       "                 in_dist_probe   balance balance_proxy roc_auc_adapter  \\\n",
       "glue:qnli                 True  0.384615      0.477667          0.6375   \n",
       "hans                      True  0.538462      0.547046        0.577381   \n",
       "super_glue:rte            True  0.464286      0.519561        0.810256   \n",
       "sst2                      True  0.608696      0.467699        0.896825   \n",
       "super_glue:axg            True  0.428571      0.541212        0.898148   \n",
       "imdb                     False  0.531915      0.485629         0.94697   \n",
       "super_glue:boolq         False  0.459119      0.475899        0.961373   \n",
       "amazon_polarity           True  0.428571      0.461685            0.98   \n",
       "\n",
       "                 roc_auc_base  \n",
       "glue:qnli             0.66875  \n",
       "hans                 0.690476  \n",
       "super_glue:rte       0.789744  \n",
       "sst2                 0.865079  \n",
       "super_glue:axg       0.976852  \n",
       "imdb                 0.945455  \n",
       "super_glue:boolq     0.935808  \n",
       "amazon_polarity          0.92  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_steps = int(len(ds_trainval)*0.7//batch_size)\n",
    "pl_model = PLSK2(c_in=c_in, epoch_steps=epoch_steps, max_epochs=max_epochs)\n",
    "model = PLSKWrapper(pl_model, verbose=verbose, max_epochs=max_epochs)\n",
    "df_res = eval_ranking(model, ds_trainval, ds_test)\n",
    "df_res2 = analyze_dfres(df_res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PL Direct classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HSModel3d(nn.Module):\n",
    "    def __init__(self, c_in, hs, dropout=0, depth=2):\n",
    "        super().__init__()\n",
    "        self.preconv = nn.Sequential(\n",
    "            nn.Conv2d(c_in[1], hs*4, (1, 2)),\n",
    "        )\n",
    "\n",
    "        layers = [nn.BatchNorm1d(hs*4, affine=False)]\n",
    "        for i in range(depth+1):\n",
    "            if (i>0) and (i<depth):\n",
    "                layers.append(InceptionBlock(hs*4, hs, conv_dropout=dropout))\n",
    "            elif i==0: # first layer\n",
    "                if depth==0: \n",
    "                    layers.append(InceptionBlock(hs*4, 1))\n",
    "                else:\n",
    "                    layers.append(InceptionBlock(hs*4, hs, conv_dropout=dropout))\n",
    "            else: # last layer\n",
    "                layers.append(nn.Conv1d(hs*4, 1, 1))\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "        \n",
    "        n = c_in[0]\n",
    "        self.head = nn.Sequential(\n",
    "            LinBnDrop(n, n, p=dropout),\n",
    "            LinBnDrop(n, n, p=dropout),\n",
    "            nn.Linear(n, 1),  \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        if x.ndim==4:\n",
    "            x = x.squeeze(3)\n",
    "        x = rearrange(x, 'b l h v -> b h l v')\n",
    "        x = self.preconv(x)\n",
    "        x = rearrange(x, 'b h l v -> b h (l v)')\n",
    "        x = self.conv(x)\n",
    "        x = rearrange(x, 'b l h -> b (l h)')\n",
    "        return self.head(x).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.helpers.sklearn_lightning import PLSKWrapper, PLSKBase\n",
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "class PLSKDirect(PLSKBase):\n",
    "    def __init__(self, c_in, dropout=0, hs=32, depth=2, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.model = HSModel3d(c_in, hs, dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set labels\n",
    "ds2proxy = ranking_truth_telling\n",
    "proxy2label = undo_ranked_truth_telling\n",
    "\n",
    "# unit test labels\n",
    "y_val1 = ds2proxy(ds_val)\n",
    "y1 = proxy2label(y_val1, ds_val)\n",
    "np.testing.assert_array_equal(y1, ds_val['label_true_base'], err_msg=\"undo_distance_truth_telling failed\")\n",
    "# assert (y1 == ds_val['label_true_base']).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 2559, 2])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train, ds_val = train_test_split_ds(ds_trainval, test_size=0.3)\n",
    "X_val, y_val_proxy = ds2xy(ds_val)\n",
    "c_in = X_val.shape[1:]\n",
    "c_in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_steps = int(len(ds_trainval)*0.7//batch_size)\n",
    "pl_model = PLSKDirect(c_in=c_in, epoch_steps=epoch_steps, max_epochs=max_epochs)\n",
    "model = PLSKWrapper(pl_model, verbose=verbose, max_epochs=max_epochs)\n",
    "df_res = eval_ranking(model, ds_trainval, ds_test)\n",
    "df_res2 = analyze_dfres(df_res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TorchDummyClassifier(random_state=42, strategy=\"most_frequent\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# split\n",
    "ds_train, ds_val = train_test_split_ds(ds_trainval, test_size=0.3)\n",
    "X_val, y_val_proxy = ds2xy(ds_val)\n",
    "X_train, y_train_proxy = ds2xy(ds_train)\n",
    "X_test, y_test = ds2xy(ds_test)\n",
    "\n",
    "# scale\n",
    "scaler = TorchRobustScaler(with_centering=False, with_scaling=True)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model.fit(X_train=X_train, y_train=y_train_proxy, X_val=X_val, y_val=y_val_proxy)\n",
    "\n",
    "# must return a single torch float probability\n",
    "y_val_proxy_prob = model.predict_proba(X_val)\n",
    "assert y_val_proxy_prob.max()<=1\n",
    "assert y_val_proxy_prob.min()>=0\n",
    "assert y_val_proxy_prob.ndim == 1, \"model must return a single probability\"\n",
    "assert y_val_proxy_prob.shape[0] == X_val.shape[0], \"model must return a single probability for each sample\"\n",
    "assert isinstance(y_val_proxy_prob, torch.Tensor), \"model must return a torch tensor\"\n",
    "assert torch.is_floating_point(y_val_proxy_prob), \"model must return a torch tensor\"\n",
    "\n",
    "\n",
    "X_test, y_test_proxy = ds2xy(ds_test)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_test_proxy_prob = model.predict_proba(X_test)\n",
    "y_test = proxy2label(y_test_proxy, ds_test)\n",
    "y_test_prob = proxy2label(y_test_proxy_prob, ds_test)\n",
    "\n",
    "\n",
    "# df_res1 = ds2dfres(model, scaler, ds_val, False)\n",
    "# df_res2 = ds2dfres(model, scaler, ds_test, False)\n",
    "# df_res = pd.concat([df_res1, df_res2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DELETEME BELOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv mse ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.helpers.torch_helpers import clear_mem, detachcpu, recursive_copy, switch\n",
    "\n",
    "def distance_truth_telling(ds):\n",
    "    \"\"\"label whether the adapter or the base model were more truthfull.\"\"\"\n",
    "    return ds['correct_truth_telling_base'] - ds['correct_truth_telling_adapt']\n",
    "\n",
    "\n",
    "def undo_distance_truth_telling(base_more_truthful: Float[Tensor, ''], ds: Dataset, ):\n",
    "    #note if we know which model is more truthful, and it's a binary choice, we can take the choice that is in that direction as the truth\n",
    "    base_more_positive = (ds['binary_ans_base'] > ds['binary_ans_adapt']) * 1.0\n",
    "    return base_more_truthful * base_more_positive + (1-base_more_positive) * (-base_more_truthful)\n",
    "    # return switch(base_more_positive, base_more_truthful)\n",
    "\n",
    "\n",
    "y = distance_truth_telling(ds_known)\n",
    "y2 = undo_distance_truth_telling(y, ds_known)\n",
    "np.testing.assert_array_equal(y2>0, ds_known['label_true_base'], err_msg=\"we should be able to undo the label transform\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(y, bins=20)\n",
    "# plt.hist(y2, bins=20)\n",
    "# plt.hist(ds_known['label_true_base']*1.0, bins=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_convrank_intervention_predictive(hs, y, verbose=True):\n",
    "\n",
    "y = distance_truth_telling(ds_known)\n",
    "X = torch.stack([hs_normal,hs_intervene], 1)\n",
    "X_train0, X_val0, X_train1, X_val1, y_train, y_val = train_test_split(hs_normal, hs_intervene, y, test_size=0.5, random_state=42, shuffle=False)\n",
    "\n",
    "to_ds = lambda hs0, hs1, y: TensorDataset(hs0, hs1, y)\n",
    "dl_train = DataLoader(to_ds(X_train0, X_train1, y_train), batch_size=batch_size, shuffle=True)\n",
    "dl_val = DataLoader(to_ds(X_val0, X_val1, y_val), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "x0, x1,y1 = next(iter(dl_train))\n",
    "c_in = x1.shape[1:]\n",
    "net = PLConvProbeLinear(c_in, epoch_steps=len(dl_train),  max_epochs=max_epochs, depth=3, lr=4e-3, weight_decay=1e-5, hs=32, dropout=0.1)\n",
    "\n",
    "from torchinfo import summary\n",
    "summary(net, input_data=x1) # input_size=(batch_size, 1, 28, 28))\n",
    "\n",
    "\n",
    "trainer1 = pl.Trainer(\n",
    "    gradient_clip_val=20,\n",
    "    # accelerator=\"auto\",\n",
    "    # devices=\"1\",\n",
    "    max_epochs=max_epochs,\n",
    "    log_every_n_steps=1,\n",
    "    enable_progress_bar=verbose,\n",
    "      enable_model_summary=verbose\n",
    ")\n",
    "trainer1.fit(model=net, train_dataloaders=dl_train, val_dataloaders=dl_val);\n",
    "\n",
    "df_hist, df_hist_step  = read_metrics_csv(trainer1.logger.experiment.metrics_file_path)\n",
    "\n",
    "df_hist[['val/acc', 'train/acc']].plot()\n",
    "df_hist[['val/loss_epoch', 'train/loss_epoch']].plot()\n",
    "# df_hist_step[['val/acc', 'train/acc']].plot(style=\".\")\n",
    "# df_hist_step[['val/loss', 'train/loss']].plot(style=\".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r = trainer1.predict(net, dataloaders=dl_val)\n",
    "y_pred_raw = torch.cat(r).flatten()\n",
    "# y_pred_prob = (y_pred_raw+1)/2\n",
    "y_pred_prob = (torch.tanh(y_pred_raw)+1)/2\n",
    "# y_val2 = y_val > 0.\n",
    "\n",
    "\n",
    "# undo label transform...\n",
    "ds_known_val = ds_known.select(range(len(ds_known)-len(y_pred_raw), len(ds_known)))\n",
    "y_val_pred_true = undo_distance_truth_telling(y_pred_prob, ds=ds_known_val)\n",
    "\n",
    "y_val3 = undo_distance_truth_telling(y_val, ds=ds_known_val)\n",
    "y_val4 = ds_known_val['label_true_base']\n",
    "np.testing.assert_array_equal(y_val3>0, y_val4, err_msg=\"make sure we used the right dataset\")\n",
    "\n",
    "y_pred = y_val_pred_true > 0.\n",
    "y_val5 = y_val3 > 0.\n",
    "\n",
    "score = roc_auc_score(y_val5, y_val_pred_true)\n",
    "print(score)\n",
    "target_names = [0, 1]\n",
    "cm = confusion_matrix(y_val5, y_pred, target_names=target_names, normalize='true')\n",
    "cr = classification_report(y_val5, y_pred, target_names=target_names)\n",
    "print(cm)\n",
    "print(cr)\n",
    "# return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_kwargs = dict(lw=2, alpha=0.75, histtype=\"step\", bins=26, range=(-2,2))\n",
    "# plt.hist(y_pred_prob, label='prob', **hist_kwargs, )\n",
    "# plt.hist(y_val2,label='pred',  **hist_kwargs,)\n",
    "# plt.hist(y_pred, label='truth',  **hist_kwargs,)\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# plt.hist(y_pred_raw, label='pred',  **hist_kwargs,)\n",
    "# plt.hist(y_val,  label='truth',  **hist_kwargs,)\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv bool ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional import accuracy, auroc, f1_score, jaccard_index, dice\n",
    "from random import random as rand\n",
    "\n",
    "class PLConvProbeBoolRank(PLConvProbeLinear):\n",
    "    def _step(self, batch, batch_idx, stage='train'):\n",
    "        x0, x1, y = batch\n",
    "\n",
    "        # if rand()>0.5:\n",
    "        #     x0, x1 = x1, x0\n",
    "        #     y = 1-y\n",
    "            \n",
    "        ypred0 = self(x0)\n",
    "        ypred1 = self(x1)\n",
    "        \n",
    "        if stage=='pred':\n",
    "            return (ypred1-ypred0).float()\n",
    "        \n",
    "        ranking_y = (y>0)*2-1 # from 0,1 to -1,1\n",
    "        loss = F.margin_ranking_loss(ypred1, ypred0, ranking_y, margin=1)\n",
    "        # loss = F.smooth_l1_loss(ypred1-ypred0, y)\n",
    "        # self.log(f\"{stage}/loss\", loss)\n",
    "        \n",
    "        y_cls = ypred1>ypred0 # switch2bool(ypred1-ypred0)\n",
    "        self.log(f\"{stage}/acc\", accuracy(y_cls, y>0, \"binary\"), on_epoch=True, on_step=False)\n",
    "        self.log(f\"{stage}/loss\", loss, on_epoch=True, on_step=False)\n",
    "        self.log(f\"{stage}/n\", len(y), on_epoch=True, on_step=False, reduce_fx=torch.sum)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def check_convrank_intervention_predictive(hs, y, verbose=True):\n",
    "\n",
    "\n",
    "def dist_truth_telling(ds):\n",
    "    \"\"\"label whether the adapter or the base model were more truthfull.\"\"\"\n",
    "    return ds['correct_truth_telling_adapt'] > ds['correct_truth_telling_base']\n",
    "\n",
    "y = dist_truth_telling(ds_known)\n",
    "X = torch.stack([hs_normal,hs_intervene], 1)\n",
    "X_train0, X_val0, X_train1, X_val1, y_train, y_val = train_test_split(hs_normal, hs_intervene, y, test_size=0.5, random_state=42)\n",
    "\n",
    "to_ds = lambda hs0, hs1, y: TensorDataset(hs0, hs1, y)\n",
    "dl_train = DataLoader(to_ds(X_train0, X_train1, y_train), batch_size=batch_size, shuffle=True)\n",
    "dl_val = DataLoader(to_ds(X_val0, X_val1, y_val), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "x0, x1,y1 = next(iter(dl_train))\n",
    "c_in = x1.shape[1:]\n",
    "net = PLConvProbeBoolRank(c_in, epoch_steps=len(dl_train),  max_epochs=max_epochs, depth=3, lr=4e-3, weight_decay=1e-5, hs=16, dropout=0.2)\n",
    "\n",
    "from torchinfo import summary\n",
    "summary(net, input_data=x1) # input_size=(batch_size, 1, 28, 28))\n",
    "\n",
    "\n",
    "trainer1 = pl.Trainer(\n",
    "    gradient_clip_val=20,\n",
    "    # accelerator=\"auto\",\n",
    "    # devices=\"1\",\n",
    "    max_epochs=max_epochs,\n",
    "    log_every_n_steps=1,\n",
    "    enable_progress_bar=verbose,\n",
    "      enable_model_summary=verbose\n",
    ")\n",
    "trainer1.fit(model=net, train_dataloaders=dl_train, val_dataloaders=dl_val);\n",
    "\n",
    "\n",
    "\n",
    "df_hist, df_hist_step  = read_metrics_csv(trainer1.logger.experiment.metrics_file_path)\n",
    "\n",
    "df_hist[['val/acc', 'train/acc']].plot()\n",
    "df_hist[['val/loss', 'train/loss']].plot()\n",
    "# df_hist_step[['val/acc', 'train/acc']].plot(style=\".\")\n",
    "# df_hist_step[['val/loss', 'train/loss']].plot(style=\".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = trainer1.predict(net, dataloaders=dl_val)\n",
    "y_pred_raw = torch.cat(r).flatten()\n",
    "y_pred_prob = (torch.tanh(y_pred_raw)+1)/2\n",
    "# y_pred = y_pred_raw > 0.\n",
    "y_val2 = y_val > 0.\n",
    "\n",
    "\n",
    "\n",
    "# undo label transform...\n",
    "ds_known_val = ds_known.select(range(len(ds_known)-len(y_pred_raw), len(ds_known)))\n",
    "y_val_pred_true = undo_ranked_truth_telling(y_pred_prob, ds=ds_known_val)\n",
    "y_val3 = undo_ranked_truth_telling(y_val2, ds=ds_known_val)\n",
    "\n",
    "y_pred = y_val_pred_true > 0.5\n",
    "\n",
    "score = roc_auc_score(y_val3, y_val_pred_true)\n",
    "print(score)\n",
    "target_names = [0, 1]\n",
    "cm = confusion_matrix(y_val3, y_pred, target_names=target_names, normalize='true')\n",
    "cr = classification_report(y_val3, y_pred, target_names=target_names)\n",
    "print(cm)\n",
    "print(cr)\n",
    "\n",
    "# return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG dist\n",
    "hist_kwargs = dict(lw=2, alpha=0.75, histtype=\"step\", bins=26, range=(-2,2))\n",
    "plt.hist(y_pred_prob, label='prob', **hist_kwargs, )\n",
    "plt.hist(y_val2,label='pred',  **hist_kwargs,)\n",
    "plt.hist(y_pred, label='truth',  **hist_kwargs,)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.hist(y_pred_raw, label='pred',  **hist_kwargs,)\n",
    "plt.hist(y_val,  label='truth',  **hist_kwargs,)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv direct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional import accuracy, auroc, f1_score, jaccard_index, dice\n",
    "from src.probes.pl_ranking_probe import LinBnDrop, InceptionBlock, PLRankingBase\n",
    "\n",
    "class PLConvProbeLinearCls(PLRankingBase):\n",
    "\n",
    "    def __init__(self, c_in, epoch_steps, max_epochs, depth=0, lr=4e-3, weight_decay=1e-9, hs=8, dropout=0, **kwargs):\n",
    "        super().__init__(epoch_steps=epoch_steps, max_epochs=max_epochs, lr=lr, weight_decay=weight_decay)\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.pre = nn.Sequential(\n",
    "            # nn.BatchNorm2d(c_in[1], affine=False),\n",
    "            nn.Conv2d(c_in[1], hs*4, (1, 2)),\n",
    "            nn.Conv2d(hs*4, hs*4, (2, 1)),\n",
    "        )\n",
    "\n",
    "        layers = [\n",
    "            nn.BatchNorm1d(hs*4, affine=False)\n",
    "            ]\n",
    "        for i in range(depth+1):\n",
    "            if (i>0) and (i<depth):\n",
    "                layers.append(InceptionBlock(hs*4, hs, conv_dropout=dropout))\n",
    "            elif i==0: # first layer\n",
    "                if depth==0: \n",
    "                    layers.append(InceptionBlock(hs*4, 1))\n",
    "                else:\n",
    "                    layers.append(InceptionBlock(hs*4, hs, conv_dropout=dropout))\n",
    "            else: # last layer\n",
    "                layers.append(nn.Conv1d(hs*4, 1, 1))\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "        \n",
    "        n = c_in[0] - 1\n",
    "        self.head = nn.Sequential(\n",
    "            LinBnDrop(n, n, p=dropout),\n",
    "            LinBnDrop(n, n, p=dropout),\n",
    "            nn.Linear(n, 1),  \n",
    "            # nn.Tanh(), \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if x.ndim==4:\n",
    "            x = x.squeeze(3)\n",
    "        x = rearrange(x, 'b l h n -> b h l n')\n",
    "        x = self.pre(x)\n",
    "        x = rearrange(x, 'b h l n -> b h (l n)')\n",
    "        x = self.conv(x)\n",
    "        x = rearrange(x, 'b l h -> b (l h)')\n",
    "        return self.head(x).squeeze(1)\n",
    "    \n",
    "    def _step(self, batch, batch_idx, stage='train'):\n",
    "        x0, y = batch\n",
    "        logits = self(x0)\n",
    "        ypred = torch.sigmoid(logits)\n",
    "        \n",
    "        if stage=='pred':\n",
    "            return ypred.float()\n",
    "        \n",
    "        loss = F.binary_cross_entropy_with_logits(logits, y.float())\n",
    "        \n",
    "        self.log(f\"{stage}/acc\", accuracy(ypred, y, \"binary\"), on_epoch=True, )\n",
    "        self.log(f\"{stage}/loss\", loss, on_epoch=True,  prog_bar=True)\n",
    "        self.log(f\"{stage}/n\", len(y), on_epoch=True, on_step=False, reduce_fx=torch.sum)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = ds2label_model_truth(ds_known)\n",
    "y = ranking_truth_telling(ds_known)\n",
    "X = torch.stack([hs_normal,hs_intervene], 3)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "to_ds = lambda hs, y: TensorDataset(hs, y)\n",
    "dl_train = DataLoader(to_ds(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "dl_val = DataLoader(to_ds(X_val, y_val), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "x1,y1 = next(iter(dl_train))\n",
    "c_in = x1.shape[1:]\n",
    "print(c_in)\n",
    "net = PLConvProbeLinearCls(c_in, epoch_steps=len(dl_train),  max_epochs=max_epochs, depth=2, lr=4e-3, weight_decay=1e-5, hs=16, dropout=0.2)\n",
    "# print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "summary(net, input_data=x1) # input_size=(batch_size, 1, 28, 28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(c_in)\n",
    "# with torch.no_grad():\n",
    "#     net(x1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "trainer1 = pl.Trainer(\n",
    "    gradient_clip_val=20,\n",
    "    # accelerator=\"auto\",\n",
    "    # devices=\"1\",\n",
    "    max_epochs=max_epochs,\n",
    "    log_every_n_steps=1,\n",
    "    enable_progress_bar=verbose, enable_model_summary=verbose\n",
    ")\n",
    "trainer1.fit(model=net, train_dataloaders=dl_train, val_dataloaders=dl_val);\n",
    "\n",
    "\n",
    "\n",
    "df_hist, df_hist_step  = read_metrics_csv(trainer1.logger.experiment.metrics_file_path)\n",
    "\n",
    "df_hist[['val/acc', 'train/acc']].plot()\n",
    "# df_hist[['val/loss', 'train/loss']].plot()\n",
    "# df_hist_step[['val/acc', 'train/acc']].plot(style=\".\")\n",
    "# df_hist_step[['val/loss', 'train/loss']].plot(style=\".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = trainer1.predict(net, dataloaders=dl_val)\n",
    "y_pred_prob = torch.cat(r).flatten()\n",
    "y_pred = y_pred_prob > 0.5\n",
    "\n",
    "score = roc_auc_score(y_val, y_pred_prob)\n",
    "\n",
    "print(score)\n",
    "target_names = [0, 1]\n",
    "cm = confusion_matrix(y_val, y_pred, target_names=target_names, normalize='true')\n",
    "cr = classification_report(y_val, y_pred, target_names=target_names)\n",
    "print(cm)\n",
    "print(cr)\n",
    "\n",
    "# return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DEBUG DIST\n",
    "# hist_kwargs = dict(lw=2, alpha=0.75, histtype=\"step\", bins=26, range=(-2,2))\n",
    "# plt.hist(y_pred_prob, label='prob', **hist_kwargs, )\n",
    "# plt.hist(y_val2,label='pred',  **hist_kwargs,)\n",
    "# plt.hist(y_pred, label='truth',  **hist_kwargs,)\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# plt.hist(y_pred_raw, label='pred',  **hist_kwargs,)\n",
    "# plt.hist(y_val,  label='truth',  **hist_kwargs,)\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "\n",
    "def ccs_loss(p_neg, p_pos):\n",
    "    consistency_losses = (p_pos - (1 - p_neg)) ** 2\n",
    "    confidence_losses = t.min(t.stack((p_pos, p_neg), dim=-1), dim=-1).values ** 2\n",
    "    return t.mean(consistency_losses + confidence_losses)\n",
    "\n",
    "class PL_CSS(PLRankingBase):\n",
    "    def __init__(self, d_in, epoch_steps: int, max_epochs: int, lr=4e-3, weight_decay=1e-9):\n",
    "        super().__init__(epoch_steps=epoch_steps, max_epochs=max_epochs, lr=lr, weight_decay=weight_decay)\n",
    "        self.model = t.nn.Sequential(\n",
    "            t.nn.Linear(d_in, 1, bias=False),\n",
    "            t.nn.Sigmoid()\n",
    "        )\n",
    "        self.total_steps = epoch_steps * max_epochs\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x.squeeze(2))\n",
    "        \n",
    "    def _step(self, batch, batch_idx, stage='train'):\n",
    "        h, y = batch\n",
    "        yb = y>0.5\n",
    "        ypred = self(h)\n",
    "        if stage=='pred':\n",
    "            return ypred\n",
    "        p_neg = ypred[~yb].mean()\n",
    "        p_pos = ypred[yb].mean()\n",
    "        loss = ccs_loss(p_neg, p_pos)\n",
    "        assert torch.isfinite(loss)\n",
    "        \n",
    "        y_cls = ypred>0.5 # switch2bool(ypred1-ypred0)\n",
    "        self.log(f\"{stage}/acc\", accuracy(y_cls, y>0, \"binary\"), on_epoch=True, on_step=False)\n",
    "        self.log(f\"{stage}/loss\", loss, on_epoch=True, on_step=True, prog_bar=True)\n",
    "        self.log(f\"{stage}/n\", len(y), on_epoch=True, on_step=False, reduce_fx=torch.sum)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_normal = ds_known['end_residual_stream_base']\n",
    "hs_intervene = ds_known['end_residual_stream_adapt']\n",
    "label_fn = ranking_truth_telling\n",
    "hs = hs_normal - hs_intervene\n",
    "y = label_fn(ds_known)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_ds = lambda hs, y: TensorDataset(hs, y)\n",
    "dl_train = DataLoader(to_ds(X_train, y_train), batch_size=128, shuffle=True)\n",
    "dl_val = DataLoader(to_ds(X_val, y_val), batch_size=128, shuffle=False)\n",
    "x, y = next(iter(dl_train))\n",
    "c_in = x.shape[1]\n",
    "\n",
    "net = PL_CSS(d_in=c_in, epoch_steps=len(dl_train),  max_epochs=max_epochs, lr=4e-4, \n",
    "             weight_decay=1e-5)\n",
    "trainer = pl.Trainer(\n",
    "    # gradient_clip_val=20,\n",
    "    # accelerator=\"auto\",\n",
    "    # devices=\"1\",\n",
    "    max_epochs=max_epochs,\n",
    "    log_every_n_steps=1,\n",
    "    enable_progress_bar=verbose, enable_model_summary=verbose\n",
    ")\n",
    "trainer.fit(model=net, train_dataloaders=dl_train, val_dataloaders=dl_val);\n",
    "\n",
    "\n",
    "df_hist, df_hist_step  = read_metrics_csv(trainer.logger.experiment.metrics_file_path)\n",
    "\n",
    "df_hist[['val/acc', 'train/acc']].plot()\n",
    "df_hist[['val/loss_epoch', 'train/loss_epoch']].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = trainer1.predict(net, dataloaders=dl_val)\n",
    "y_pred_prob = torch.cat(r).flatten()\n",
    "y_pred = y_pred_prob > 0.5\n",
    "\n",
    "score = roc_auc_score(y_val, y_pred_prob)\n",
    "\n",
    "print(score)\n",
    "target_names = [0, 1]\n",
    "cm = confusion_matrix(y_val, y_pred, target_names=target_names, normalize='true')\n",
    "cr = classification_report(y_val, y_pred, target_names=target_names)\n",
    "print(cm)\n",
    "print(cr)\n",
    "\n",
    "# return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conformal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, ComplementNB, MultinomialNB\n",
    "from mapie.classification import MapieClassifier\n",
    "\n",
    "layers = X.shape[1]\n",
    "X = rearrange(hs, 'b l hs -> b (l hs)')\n",
    "X_train, X_val, y_train, y_val = preproc(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced',).fit(X_train, y_train)\n",
    "mapie = MapieClassifier(estimator=clf, cv=\"prefit\",\n",
    "                        # method=\"score\",                        \n",
    "                        ).fit(X_train, y_train)\n",
    "y_val_prob, y_val_pred = mapie.predict(X_val, alpha=0.2)\n",
    "r = postproc(y_val_prob, y_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
