{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick notebook to check model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from IPython.display import display, HTML, Markdown\n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset\n",
    "from loguru import logger\n",
    "import sys\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForMaskedLM, AutoModelForCausalLM, AutoConfig, PreTrainedTokenizerBase, PreTrainedTokenizer, GPTQConfig, BitsAndBytesConfig\n",
    "\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, format=\"{time} {level} {message}\", level=\"INFO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load my code\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.eval.collect import manual_collect2\n",
    "from src.eval.ds import ds2df, qc_ds, qc_dsdf\n",
    "from src.prompts.prompt_loading import load_prompts, format_prompt, load_preproc_dataset\n",
    "from src.models.load import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]\n",
      "Generating train split: 0 examples [00:00, ? examples/s]/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/.venv/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n",
      "2023-12-22T09:52:15.018878+0800 INFO Extracting 11 variants of each prompt\n",
      "Generating train split: 242 examples [00:41,  5.78 examples/s]\n",
      "format_prompt: 100%|██████████| 242/242 [00:00<00:00, 7983.12 examples/s]\n",
      "tokenize: 100%|██████████| 242/242 [00:00<00:00, 2793.65 examples/s]\n",
      "truncated: 100%|██████████| 242/242 [00:00<00:00, 2179.98 examples/s]\n",
      "truncated: 100%|██████████| 242/242 [00:00<00:00, 2561.22 examples/s]\n",
      "prompt_truncated: 100%|██████████| 242/242 [00:00<00:00, 371.00 examples/s]\n",
      "choice_ids: 100%|██████████| 242/242 [00:00<00:00, 7571.74 examples/s]\n",
      "2023-12-22T09:52:55.197613+0800 INFO median token length: 358.0 for amazon_polarity. max_length=999\n",
      "2023-12-22T09:52:55.198160+0800 INFO truncation rate: 0.00% on amazon_polarity\n",
      "Filter: 100%|██████████| 242/242 [00:00<00:00, 2250.36 examples/s]\n",
      "Filter: 100%|██████████| 242/242 [00:00<00:00, 1894.39 examples/s]\n",
      "2023-12-22T09:52:55.440518+0800 INFO num_rows (after filtering out truncated rows) 242=>242\n",
      "2023-12-22T09:52:59.147153+0800 INFO creating dataset /media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/.ds/ds__3772657c76ea678f\n",
      "collecting hidden states:   0%|          | 0/20 [00:00<?, ?it/s]2023-12-22T09:53:01.087806+0800 WARNING model does not have disable_adapter\n",
      "collecting hidden states:   5%|▌         | 1/20 [00:02<00:41,  2.20s/it]2023-12-22T09:53:03.181556+0800 WARNING model does not have disable_adapter\n",
      "collecting hidden states:  10%|█         | 2/20 [00:04<00:39,  2.21s/it]2023-12-22T09:53:05.313142+0800 WARNING model does not have disable_adapter\n",
      "collecting hidden states:  15%|█▌        | 3/20 [00:06<00:35,  2.12s/it]2023-12-22T09:53:07.328624+0800 WARNING model does not have disable_adapter\n",
      "collecting hidden states:  20%|██        | 4/20 [00:08<00:33,  2.10s/it]2023-12-22T09:53:09.423942+0800 WARNING model does not have disable_adapter\n",
      "collecting hidden states:  25%|██▌       | 5/20 [00:10<00:31,  2.08s/it]2023-12-22T09:53:11.434048+0800 WARNING model does not have disable_adapter\n",
      "collecting hidden states:  30%|███       | 6/20 [00:12<00:29,  2.09s/it]2023-12-22T09:53:13.517246+0800 WARNING model does not have disable_adapter\n",
      "collecting hidden states:  35%|███▌      | 7/20 [00:14<00:26,  2.05s/it]2023-12-22T09:53:15.489134+0800 WARNING model does not have disable_adapter\n",
      "collecting hidden states:  40%|████      | 8/20 [00:16<00:24,  2.03s/it]2023-12-22T09:53:17.498677+0800 WARNING model does not have disable_adapter\n",
      "collecting hidden states:  45%|████▌     | 9/20 [00:18<00:22,  2.02s/it]2023-12-22T09:53:19.480665+0800 WARNING model does not have disable_adapter\n",
      "collecting hidden states:  50%|█████     | 10/20 [00:20<00:20,  2.02s/it]"
     ]
    }
   ],
   "source": [
    "model_ids = [\n",
    "    \"malhajar/phi-2-chat\",\n",
    "    \"Yhyu13/phi-2-sft-alpaca_gpt4_en-ep1\", # has benchmark!\n",
    "    \"venkycs/phi-2-ultrachat200k\",\n",
    "    \"Walmart-the-bag/phi-2-uncensored\",\n",
    "    \"Mit1208/phi-2-universal-NER\", # named entity recognition\n",
    "    \"chendelong/phi-2-finetuned-dialogstudio\",\n",
    "    \"TharunSiva/phi-2-oasst1-100steps\", # ?\n",
    "    \"Yhyu13/LMCocktail-phi-2-v1\", # merge\n",
    "\n",
    "]\n",
    "N = 80\n",
    "res = {}\n",
    "for model_id in model_ids:\n",
    "    print(model_id)\n",
    "\n",
    "    # load model\n",
    "    model, tokenizer = load_model(model_id, dtype=torch.float16)\n",
    "\n",
    "    # load dataset\n",
    "    ds = load_preproc_dataset(\"amazon_polarity\", tokenizer, N).with_format(\"torch\")\n",
    "\n",
    "    # eval\n",
    "    dl = DataLoader(ds, batch_size=4, shuffle=False, num_workers=0)\n",
    "    ds_out, f = manual_collect2(dl, model, get_residual=False)\n",
    "    print(f'for {model_id}:')\n",
    "    try:\n",
    "        qc_ds(ds_out)\n",
    "    except AssertionError as e:\n",
    "        print(e)\n",
    "    except:\n",
    "        logger.exception(f'failed for {model_id}')\n",
    "\n",
    "    # record overall acc\n",
    "    df = ds2df(ds)\n",
    "    df = df.rename(columns=lambda x: x.replace('_base', '')).copy()\n",
    "    d = df.query('instructed_to_lie==False')\n",
    "    acc = (d.label_instructed==d['ans']).mean()\n",
    "    res[model_id] = acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\tfor malhajar/phi-2-chat:\n",
    "\twith base model\n",
    "\t\tbalance=\t45.71% [N=35]\n",
    "\t\tacc    =\t47.06% [N=17]      - when the model is not lying... we get this task acc\n",
    "\t\tlie_acc=\t61.11% [N=18]      - when the model tries to lie... we get this acc\n",
    "\t\tknown_lie_acc=\t100.00% [N=2]      - when the model tries to lie and knows the answer... we get this acc\n",
    "\t\tchoice_cov=\t0.50%             - Our choices accounted for a mean probability of this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
