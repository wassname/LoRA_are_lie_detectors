{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm I should be able to calculate the truth from any label I use right? Let's check that!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "plt.style.use(['seaborn-v0_8', 'seaborn-v0_8-paper'])\n",
    "# plt.style.use(\"ggplot\")\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load my code\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.datasets.dm import DeceptionDataModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "MAX_SAMPLES = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/.venv/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3204,\n",
       " Dataset({\n",
       "     features: ['end_logits_base', 'choice_probs_base', 'binary_ans_base', 'label_true_base', 'label_instructed_base', 'instructed_to_lie_base', 'sys_instr_name_base', 'example_i_base', 'ds_string_base', 'template_name_base', 'correct_truth_telling_base', 'correct_instruction_following_base', 'end_residual_stream_base', 'end_logits_adapt', 'choice_probs_adapt', 'binary_ans_adapt', 'label_true_adapt', 'label_instructed_adapt', 'instructed_to_lie_adapt', 'sys_instr_name_adapt', 'example_i_adapt', 'ds_string_adapt', 'template_name_adapt', 'correct_truth_telling_adapt', 'correct_instruction_following_adapt', 'end_residual_stream_adapt'],\n",
       "     num_rows: 1000\n",
       " }))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_ood = '/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/.ds/ds_OOD_6d3ece46c44f6c3b'\n",
    "f1_val = '/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/.ds/ds_valtest_73b754e8fdff9f2f'\n",
    "\n",
    "ds_val = Dataset.from_file(f1_val).with_format(\"torch\")\n",
    "\n",
    "ds_oos = Dataset.from_file(f1_ood).with_format(\"torch\")\n",
    "\n",
    "ds_out1 = datasets.interleave_datasets([ds_val, ds_val])\n",
    "ds_out = ds_out1.select(range(MAX_SAMPLES))\n",
    "len(ds_out1), ds_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.eval.labels import ranking_truth_telling, ranking_instruction_following\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = ds['label_true_base']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model score: 80.72%\n",
      "Adapt model score: 90.98%\n"
     ]
    }
   ],
   "source": [
    "# binary_ans is just the binary prediction\n",
    "score = roc_auc_score(y_true, ds['binary_ans_base'])\n",
    "print(f\"Base model score: {score:.2%}\")\n",
    "\n",
    "score = roc_auc_score(y_true, ds['binary_ans_adapt'])\n",
    "print(f\"Adapt model score: {score:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ranking_truth_telling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.eval.labels import ranking_truth_telling, undo_ranked_truth_telling\n",
    "\n",
    "\n",
    "# UNIT TEST\n",
    "y_true = ds['label_true_base']\n",
    "base_more_truthfull = ranking_truth_telling(ds) * 0.9\n",
    "y_true_from_rank = undo_ranked_truth_telling(ds, base_more_truthfull)>0.5\n",
    "\n",
    "np.testing.assert_array_equal(y_true, y_true_from_rank)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ranking_instruction_following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_instruction_following\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_res_ab_o' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/notebooks/06_check_labels.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/notebooks/06_check_labels.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meval\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlabels\u001b[39;00m \u001b[39mimport\u001b[39;00m ranking_truth_telling, ranking_instruction_following\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/notebooks/06_check_labels.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df_res_ab_o, df_res_o\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/notebooks/06_check_labels.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m ds \u001b[39m=\u001b[39m ds_out_OOD\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/notebooks/06_check_labels.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m a \u001b[39m=\u001b[39m ds2label_model_truth(ds)\u001b[39m.\u001b[39mnumpy()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_res_ab_o' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "df_res_ab_o, df_res_o\n",
    "ds = ds_out_OOD\n",
    "a = ds2label_model_truth(ds).numpy()\n",
    "t = ds['label_true_base']\n",
    "\n",
    "# a = ds2label_model_obey(ds_out_OOD)\n",
    "b = (ds['binary_ans_base'].numpy()>0.5) ^ (ds['correct_truth_telling_base']>0.5).numpy()\n",
    "\n",
    "c = ranking_truth_telling(ds).numpy()\n",
    "c = c * ds['correct_truth_telling_adapt'].numpy()\n",
    "\n",
    "# c = ranking_instruction_following(ds_out_OOD)\n",
    "# ds_out_OOD['correct_truth_telling_adapt']\n",
    "# ds_out_OOD['correct_instruction_following_base']\n",
    "# ds_out_OOD['correct_instruction_following_adapt']\n",
    "# plt.scatter(a, b, c=c, cmap='RdYlGn')\n",
    "# plt.show()\n",
    "# plt.scatter(a, c, c=b, cmap='RdYlGn')\n",
    "\n",
    "df_labels = pd.DataFrame([t, a, b, c], index=['label', 'model_true', 'correct_truth_telling_base', 'ranking_truth_telling']).T\n",
    "df_labels.corr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jointplot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://github.com/lingo-mit/lm-truthfulness/blob/master/lm_truthfulness_gpt-j.ipynb\n",
    "# import seaborn as sns\n",
    "# g = sns.JointGrid(data=df, x=\"lm\", y=\"probe\", hue=\"type\", xlim=(0, 1), ylim=(0, 1), space=0, palette=palette)\n",
    "# g.plot_joint(\n",
    "#     sns.histplot, #discrete=(True, False),\n",
    "#     binrange=[0, 1],\n",
    "#     bins=20,\n",
    "#     #cmap=\"gist_gray_r\",\n",
    "# )\n",
    "# g.plot_marginals(\n",
    "#     sns.histplot, multiple=\"stack\",\n",
    "#     binrange=[0, 1],\n",
    "#     bins=20,\n",
    "#     #color=\"gray\",\n",
    "\n",
    "# )\n",
    "# g.figure.axes[0].set_xticks([0, 0.5, 1])\n",
    "# g.figure.axes[0].set_yticks([0, 0.5, 1])\n",
    "# g.figure.axes[0].set_axisbelow(False)\n",
    "# g.figure.axes[0].grid(color=\"black\")\n",
    "# g.figure.axes[0].get_legend().remove()\n",
    "# #g.plot_joint(sns.scatterplot, sns.histplot)\n",
    "# #g = sns.jointplot(data=df, x=\"lm\", y=\"probe\")\n",
    "# plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
