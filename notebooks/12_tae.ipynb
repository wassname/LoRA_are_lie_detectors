{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying a tokenized autoencoder\n",
    "\n",
    "E.g. from IRIS https://github.dev/eloialonso/iris where sparsity is enforced by the tokenization/embedding quantisation bottleneck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "from typing import Optional, List, Dict, Union\n",
    "from jaxtyping import Float\n",
    "from torch import Tensor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import Tensor\n",
    "from torch import optim\n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset\n",
    "\n",
    "from pathlib import Path\n",
    "from einops import rearrange\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    AutoConfig,\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_config,\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    TaskType,\n",
    "    LoftQConfig,\n",
    "    IA3Config,\n",
    ")\n",
    "from pathlib import Path\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "logger.add(os.sys.stderr, format=\"{time} {level} {message}\", level=\"INFO\")\n",
    "\n",
    "# load my code\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "from src.config import ExtractConfig\n",
    "from src.llms.load import load_model\n",
    "from src.helpers.torch_helpers import clear_mem\n",
    "from src.llms.phi.model_phi import PhiForCausalLMWHS\n",
    "from src.eval.ds import filter_ds_to_known\n",
    "from src.datasets.act_dm import ActivationDataModule\n",
    "\n",
    "# plt.style.use(\"ggplot\")\n",
    "# plt.style.use(\"seaborn-v0_8\")\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set_theme(\"paper\")\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.WARNING)\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", \".*sampler has shuffling enabled, it is strongly recommended that.*\"\n",
    ")\n",
    "# warnings.filterwarnings(\"ignore\", \".*has been removed as a dependency of.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TQDM_MININTERVAL\"] = \"9\"\n",
    "# os.environ[\"TQDM_DISABLE\"] = \"1\"\n",
    "\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paramsnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "# params\n",
    "batch_size = 32\n",
    "lr = 4e-3\n",
    "wd = 0  # 1e-5\n",
    "\n",
    "MAX_ROWS = 2000\n",
    "\n",
    "SKIP = 15  # skip initial N layers\n",
    "STRIDE = 3  # skip every N layers\n",
    "DECIMATE = 1  # discard N features for speed\n",
    "\n",
    "device = \"cuda:0\"\n",
    "max_epochs = 84\n",
    "\n",
    "l1_coeff = 1e-2  # 0.5  # neel uses 3e-4 ! https://github.dev/neelnanda-io/1L-Sparse-Autoencoder/blob/bcae01328a2f41d24bd4a9160828f2fc22737f75/utils.py#L106, but them they sum l1 where mean l2\n",
    "# x_feats=x_feats. other use 1e-1\n",
    "# in ai saftey foundation. They use l1_coefficient=Parameter(max=0.03, min=0.008),\n",
    "\n",
    "\n",
    "BASE_FOLDER = Path(\n",
    "    \"/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/notebooks/lightning_logs/version_24/\"\n",
    ")\n",
    "layers_names = (\"fc1\", \"Wqkv\",\n",
    "                #  \"fc2\", \"out_proj\"\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load hidden state from a previously loaded adapter\n",
    "# the columns with _base are from the base model, and adapt from adapter\n",
    "# FROM TRAINING TRUTH\n",
    "f1_val = next(iter(BASE_FOLDER.glob(\"hidden_states/.ds/ds_valtest_*\")))\n",
    "f1_ood = next(iter(BASE_FOLDER.glob(\"hidden_states/.ds/ds_OOD_*\")))\n",
    "f1_val, f1_ood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = (\n",
    "    [\"binary_ans_base\", \"binary_ans_adapt\"]\n",
    "    + [f\"end_residual_{layer}_base\" for layer in layers_names]\n",
    "    + [f\"end_residual_{layer}_adapt\" for layer in layers_names]\n",
    ")\n",
    "\n",
    "\n",
    "def ds2xy_batched(ds):\n",
    "    data = []\n",
    "    for layer in layers_names:\n",
    "        # Stack the base and adapter representations as a 4th dim\n",
    "        X1 = [ds[f\"end_residual_{layer}_base\"], ds[f\"end_residual_{layer}_adapt\"]]\n",
    "        X1 = rearrange(X1, \"versions b l f  -> b l f versions\")[..., 0]\n",
    "        data.append(X1)\n",
    "\n",
    "    # concat layers\n",
    "    # x = rearrange(data, 'b parts l f v -> b l (parts f) v')\n",
    "    X = torch.concat(data, dim=2)[:, SKIP::STRIDE, ::DECIMATE]\n",
    "\n",
    "    y = ds[\"binary_ans_base\"] - ds[\"binary_ans_adapt\"]\n",
    "    return dict(X=X, y=y)\n",
    "\n",
    "\n",
    "def prepare_ds(ds):\n",
    "    \"\"\"\n",
    "    prepare a dataset for training\n",
    "\n",
    "    this should front load much of the computation\n",
    "    it should restrict it to the needed rows X and y\n",
    "\n",
    "    \"\"\"\n",
    "    ds = (\n",
    "        ds.with_format(\"torch\")\n",
    "        .select_columns(input_columns)\n",
    "        .map(ds2xy_batched, batched=True, batch_size=128, remove_columns=input_columns)\n",
    "    )\n",
    "    return ds\n",
    "\n",
    "\n",
    "def load_file_to_dm(f, stage):\n",
    "    ds1 = Dataset.from_file(str(f1_val), in_memory=True).with_format(\"torch\")\n",
    "    ds1 = filter_ds_to_known(ds1, verbose=True, true_col=\"truth\")\n",
    "    ds = prepare_ds(ds1)\n",
    "\n",
    "    # limit size\n",
    "    MAX_SAMPLES = min(len(ds), MAX_ROWS * 2)\n",
    "    ds = ds.select(range(0, MAX_SAMPLES))\n",
    "\n",
    "    dm = ActivationDataModule(ds, f.stem, batch_size=batch_size, num_workers=0)\n",
    "    dm.setup(stage)\n",
    "    dm.dm_orig = ds1\n",
    "    return dm\n",
    "\n",
    "\n",
    "dm = load_file_to_dm(f1_val, \"train\")\n",
    "dm_ood = load_file_to_dm(f1_ood, \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_ood.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = dm.train_dataloader()\n",
    "dl_val = dm.val_dataloader()\n",
    "dl_test = dm.test_dataloader()\n",
    "dl_ood = dm_ood.all_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with dataloading speeds:\n",
    "- does it help to save the Xy dataset to disc, then load, while keeping in mem?. no not faster at all\n",
    "- does it help to use num_workers > 0? yes 3x faster\n",
    "- the shared dataset wrapper is 10x faster, and less mem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get importance matrix from adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.probes.importance_matrix import get_importance_matrix\n",
    "\n",
    "\n",
    "f = f\"{BASE_FOLDER}/checkpoint_last/adapter_model.safetensors\"\n",
    "importance_matrix = get_importance_matrix(f, layers=layers_names)[\n",
    "    SKIP::STRIDE, ::DECIMATE\n",
    "]\n",
    "\n",
    "\n",
    "# importance_matrix = importance_matrix ** 3 # square to make it positive\n",
    "importance_matrix = (importance_matrix - 1).abs() ** 2\n",
    "\n",
    "\n",
    "# importance_matrix = importance_matrix / (0.1*importance_matrix.std())\n",
    "# importance_matrix = importance_matrix + 1\n",
    "\n",
    "# square to make it positive\n",
    "# importance_matrix = importance_matrix.clamp(0, None)\n",
    "# importance_matrix -= importance_matrix.mean() - 1\n",
    "\n",
    "s = importance_matrix.std()\n",
    "importance_matrix = (importance_matrix > s * 3) * 1.0\n",
    "print(f\"keeping top {importance_matrix.mean():2.2%} of features\")\n",
    "importance_matrix = importance_matrix / importance_matrix.mean()\n",
    "\n",
    "plt.hist(importance_matrix.flatten(), bins=155)\n",
    "\n",
    "importance_matrix.mean()\n",
    "\n",
    "importance_matrix = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((importance_matrix>0)*1.0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_test2 = dm.datasets['test']\n",
    "# shape1 = ds_test2[0][0].shape\n",
    "# shape2= importance_matrix.shape\n",
    "# np.testing.assert_equal(shape1, shape2, err_msg=\"shape mismatch between ds and importance matrix\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.eval.ds import ds2df\n",
    "\n",
    "\n",
    "def get_acc_subset(df, query, verbose=True):\n",
    "    assert (df[\"y\"].mean() < 0).any(), \"y should be [-1, 1]\"\n",
    "    assert (df[\"y\"].mean() > -1).all(), \"y should be [-1, 1]\"\n",
    "    assert (df[\"y\"].mean() < 1).all(), \"y should be [-1, 1]\"\n",
    "    assert (df[\"probe_pred\"].mean() > 0).all(), \"pred should be [0,1]\"\n",
    "    assert (df[\"probe_pred\"].mean() < 1).all(), \"pred should be [0,1]\"\n",
    "\n",
    "    if query:\n",
    "        df = df.query(query)\n",
    "    # df[\"probe_cls\"] = df[\"probe_pred\"] > 0.5\n",
    "    acc = ((df[\"probe_pred\"] > 0.5) == (df[\"y\"] > 0)).mean()\n",
    "    if verbose:\n",
    "        print(f\"acc={acc:2.2%},\\tn={len(df)},\\t[{query}] \")\n",
    "    return acc\n",
    "\n",
    "\n",
    "def calc_metrics(dm, net, trainer=None, split=\"test\", verbose=True):\n",
    "    # predict\n",
    "    dl_test = dm.create_dataloader(split)\n",
    "    if trainer is None:\n",
    "        trainer = pl.Trainer(\n",
    "            logger=False, enable_progress_bar=False, enable_model_summary=False\n",
    "        )\n",
    "    rt = trainer.predict(net, dataloaders=dl_test)\n",
    "    y_test_pred = np.concatenate(rt)\n",
    "\n",
    "    # get original df\n",
    "    splits = dm.splits[split]\n",
    "    df = ds2df(dm.dm_orig).rename(columns=lambda s: s.replace(\"_base\", \"\"))\n",
    "    df[\"y\"] = dm.ds[\"y\"]\n",
    "    df_test = df.iloc[splits[0] : splits[1]].copy()\n",
    "    df_test[\"probe_pred\"] = y_test_pred\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"probe results on subsets of the data for {split}\")\n",
    "    acc = get_acc_subset(df_test, \"\", verbose=verbose)\n",
    "    get_acc_subset(\n",
    "        df_test, \"instructed_to_lie==True\", verbose=verbose\n",
    "    )  # it was ph told to lie\n",
    "    get_acc_subset(\n",
    "        df_test, \"instructed_to_lie==False\", verbose=verbose\n",
    "    )  # it was told not to lie\n",
    "    get_acc_subset(\n",
    "        df_test, \"ans==label_true\", verbose=verbose\n",
    "    )  # the llm gave the true ans\n",
    "    get_acc_subset(\n",
    "        df_test, \"ans==label_instructed\", verbose=verbose\n",
    "    )  # the llm gave the desired ans\n",
    "    acc_lie_lie = get_acc_subset(\n",
    "        df_test, \"instructed_to_lie==True & ans==label_instructed\", verbose=verbose\n",
    "    )  # it was told to lie, and it did lie\n",
    "    acc_lie_truth = get_acc_subset(\n",
    "        df_test, \"instructed_to_lie==True & ans!=label_instructed\", verbose=verbose\n",
    "    )\n",
    "\n",
    "    a = get_acc_subset(\n",
    "        df_test, \"instructed_to_lie==False & ans==label_instructed\", verbose=False\n",
    "    )\n",
    "    b = get_acc_subset(\n",
    "        df_test, \"instructed_to_lie==False & ans!=label_instructed\", verbose=False\n",
    "    )\n",
    "    c = get_acc_subset(\n",
    "        df_test, \"instructed_to_lie==True & ans==label_instructed\", verbose=False\n",
    "    )\n",
    "    d = get_acc_subset(\n",
    "        df_test, \"instructed_to_lie==True & ans!=label_instructed\", verbose=False\n",
    "    )\n",
    "\n",
    "    df_confusion = pd.DataFrame(\n",
    "        [[a, b], [c, d]],\n",
    "        index=[\"tell a truth\", \"tell a lie\"],\n",
    "        columns=[\"did\", \"didn't\"],\n",
    "    )\n",
    "    df_confusion.index.name = \"instructed to\"\n",
    "    df_confusion.columns.name = \"llm gave\"\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"⭐PRIMARY METRIC⭐ acc={acc:2.2%} from probe on {split}\")\n",
    "        print(\n",
    "            f\"⭐SECONDARY METRIC⭐ acc_lie_lie={acc_lie_lie:2.2%} from probe on {split}\"\n",
    "        )\n",
    "\n",
    "    print(\"\\n\\nprobe accuracy for quadrants:\")\n",
    "    print(df_confusion.round(2).to_markdown())\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    return dict(\n",
    "        acc=acc,\n",
    "        acc_lie_lie=acc_lie_lie,\n",
    "        acc_lie_truth=acc_lie_truth,\n",
    "        df_test=df_test,\n",
    "        df_confusion=df_confusion,\n",
    "    )\n",
    "\n",
    "\n",
    "# r = testval_metrics = calc_metrics(dm, trainer3, net, use_val=True)\n",
    "# r['df_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize latent space\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "def plot_latent(latent):\n",
    "    # plot image of latent space \n",
    "    vmax = latent.abs().max()\n",
    "    for i in range(4): # first 4 batches\n",
    "        plt.subplot(2, 2, i + 1)\n",
    "        vmax = latent[i].max()\n",
    "        plt.imshow(\n",
    "            latent[i],\n",
    "            cmap=cm.coolwarm,\n",
    "            interpolation=\"none\",\n",
    "            aspect=\"auto\",\n",
    "            vmin=-vmax,\n",
    "            vmax=vmax,\n",
    "        )\n",
    "        plt.title(f\"batch {i}\")\n",
    "        plt.ylabel(\"layer\")\n",
    "        plt.xlabel(\"neuron\")\n",
    "        if i < 2:\n",
    "            plt.xlabel(\"\")\n",
    "            plt.xticks([])\n",
    "        if i % 2 == 1:\n",
    "            plt.ylabel(\"\")\n",
    "            plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.colorbar()\n",
    "    # plt.colorbar()\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "    plt.show()\n",
    "\n",
    "    # histogram\n",
    "    latentf = rearrange(latent, \"b l n -> (b n) l\").T#.flatten()\n",
    "    print(latentf.shape)\n",
    "    for i in range(latent.shape[1]):\n",
    "        plt.hist(latentf[i], bins=25,\n",
    "                histtype=\"step\", log=True, label=f\"layer {i}\", density=True)\n",
    "    plt.title(\"latents by layer\")\n",
    "    plt.xlabel('latent magnitude')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# plot_latent(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.helpers.lightning import read_metrics_csv, plot_hist, rename_pl_test_results\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sparse_autoencoder.autoencoder.model import SparseAutoencoderConfig, SparseAutoencoder\n",
    "# from src.vae.sae2 import AutoEncoder, AutoEncoderConfig\n",
    "from src.iris.tokenizer import Tokenizer\n",
    "from src.iris.nets import EncoderDecoderConfig, Encoder, Decoder\n",
    "from src.vae.conv_inception import (\n",
    "    LinBnDrop,\n",
    "    PLBase,\n",
    "    recursive_requires_grad,\n",
    "    accuracy,\n",
    "    auroc,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dl_train), len(dl_val))\n",
    "b = next(iter(dl_train))\n",
    "x, y = b  # b['X'], b['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coder_cfg = EncoderDecoderConfig(\n",
    "#     resolution=64,\n",
    "#     in_channels=3,\n",
    "#     z_channels=512,\n",
    "#     ch=64,\n",
    "#     ch_mult=[1, 1, 1, 1, 1],\n",
    "#     num_res_blocks=2,\n",
    "#     attn_resolutions=[8, 16],\n",
    "#     out_ch=3,\n",
    "#     dropout=0.0,\n",
    "# )\n",
    "# encoder=Encoder(config=coder_cfg)\n",
    "# decoder=Decoder(config=coder_cfg)\n",
    "\n",
    "from src.vae.sae2 import AutoEncoderConfig, Encoder, Decoder, Affines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PLAE(PLBase):\n",
    "    def __init__(\n",
    "        self,\n",
    "        c_in,\n",
    "        steps_per_epoch,\n",
    "        max_epochs,\n",
    "        lr=4e-3,\n",
    "        weight_decay=0,\n",
    "        n_latent=512,\n",
    "        dropout=0,\n",
    "        encoder_sizes=[],\n",
    "        importance_matrix=None,\n",
    "        tokens_per_layer=6,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            max_epochs=max_epochs,\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay,\n",
    "        )\n",
    "        self.save_hyperparameters()\n",
    "        self.importance_matrix = importance_matrix\n",
    "\n",
    "        vocab_size = n_latent\n",
    "        embed_dim = n_latent\n",
    "\n",
    "\n",
    "        n_layers, n_channels = c_in\n",
    "        self.norm = Affines(n_layers, n_channels)\n",
    "        self.ae_cfg = AutoEncoderConfig(\n",
    "            n_instances=n_layers,\n",
    "            n_input_ae=n_channels,\n",
    "            n_hidden_ae=vocab_size * tokens_per_layer, # output size of decoder (tokens)\n",
    "            encoder_sizes=encoder_sizes,\n",
    "        )\n",
    "        encoder = Encoder(self.ae_cfg)\n",
    "\n",
    "        self.ae_cfg = AutoEncoderConfig(\n",
    "            n_instances=n_layers,\n",
    "            n_input_ae=n_channels,\n",
    "            n_hidden_ae=embed_dim * tokens_per_layer, # input channel to decoder (embedded tokens)\n",
    "            encoder_sizes=encoder_sizes,\n",
    "        )\n",
    "        decoder = Decoder(self.ae_cfg)\n",
    "        \n",
    "\n",
    "        self.ae = Tokenizer(\n",
    "            vocab_size=vocab_size,\n",
    "            embed_dim=embed_dim,\n",
    "            tokens_per_layer=tokens_per_layer,\n",
    "            encoder=encoder,\n",
    "            decoder=decoder,\n",
    "        )\n",
    "\n",
    "\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        n = embed_dim * n_layers * tokens_per_layer\n",
    "        self.head = nn.Sequential(\n",
    "            # LinBnDrop(n, n, bn=False, dropout=dropout),\n",
    "            # LinBnDrop(n, n // 4, dropout=dropout, bn=False),\n",
    "            # LinBnDrop(n // 4, n // 12, bn=False),\n",
    "            nn.Linear(n, 1),\n",
    "        )\n",
    "        self._ae_mode = True\n",
    "\n",
    "    def ae_mode(self, mode=0):\n",
    "        \"\"\"\n",
    "        mode 0, train the ae\n",
    "        mode 1, train only the prob\n",
    "        mode 2, train both\n",
    "        \"\"\"\n",
    "        if mode == 0:\n",
    "            print(\"training ae\")\n",
    "        elif mode == 1:\n",
    "            print(\"training probe\")\n",
    "        elif mode == 2:\n",
    "            print(\"training both ae and probe\")\n",
    "        self._ae_mode = mode\n",
    "        recursive_requires_grad(self.ae, mode in [0, 2])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        o = self.ae.encode(x)\n",
    "        z, z_q, tokens = o.z, o.z_quantized, o.tokens\n",
    "        h_rec = self.ae.decode(z_q)\n",
    "        h_rec = self.norm.inv(h_rec)\n",
    "        losses = self.ae.compute_loss(x)\n",
    "        loss = losses.loss_total\n",
    "\n",
    "        # # Note: this uses the decoders tokenization\n",
    "        # latent = z_q\n",
    "        # # but in other works there is a separate decoder for the probe\n",
    "        latent = self.embed(tokens)\n",
    "\n",
    "        latent2 = rearrange(latent, \"b l h v -> b (l h v)\")\n",
    "        pred = self.head(latent2).squeeze(1)\n",
    "        return dict(\n",
    "            pred=pred,\n",
    "            loss=loss,\n",
    "            latent=latent,\n",
    "            z=z, \n",
    "            tokens=tokens,\n",
    "            h_rec=h_rec,\n",
    "            **losses.intermediate_losses\n",
    "        )\n",
    "\n",
    "    # def on_after_backward(self):\n",
    "    #     self.ae.post_backwards_hook()\n",
    "\n",
    "    def _step(self, batch, batch_idx, stage=\"train\"):\n",
    "        device = next(self.parameters()).device\n",
    "        x, y = batch  # batch['X'], batch['y']\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        x0 = x  # [..., 0]\n",
    "        # x1 = x[..., 1]\n",
    "        info0 = self(x0)\n",
    "        # info1 = self(x1)\n",
    "        # ypred1 = info1[\"pred\"]\n",
    "        logits = info0[\"pred\"]\n",
    "        y_probs = F.sigmoid(logits)\n",
    "        y_cls = y_probs > 0.5\n",
    "\n",
    "        if stage == \"pred\":\n",
    "            return (y_probs).float()\n",
    "\n",
    "        pred_loss = F.binary_cross_entropy_with_logits(logits, (y > 0.0).float())\n",
    "\n",
    "        # pred_loss = F.smooth_l1_loss(ypred0, y)\n",
    "        rec_loss = info0[\"loss\"]\n",
    "        # l1_loss = info0[\"l1_loss\"].mean()\n",
    "        # l2_loss = info0[\"l2_loss\"].mean()\n",
    "\n",
    "        if self._ae_mode in [1, 2]:\n",
    "            self.log(\n",
    "                f\"{stage}/auroc\",\n",
    "                auroc(y_probs, y > 0, \"binary\"),\n",
    "                on_epoch=True,\n",
    "                on_step=False,\n",
    "            )\n",
    "            self.log(\n",
    "                f\"{stage}/acc\",\n",
    "                accuracy(y_cls, y > 0, \"binary\"),\n",
    "                on_epoch=True,\n",
    "                on_step=False,\n",
    "            )\n",
    "            self.log(\n",
    "                f\"{stage}/loss_pred\",\n",
    "                float(pred_loss),\n",
    "                on_epoch=True,\n",
    "                on_step=True,\n",
    "            )\n",
    "        if self._ae_mode in [0, 2]:\n",
    "            self.log(\n",
    "                f\"{stage}/loss_rec\",\n",
    "                float(rec_loss),\n",
    "                on_epoch=True,\n",
    "                on_step=True,\n",
    "            )\n",
    "            self.log(f\"{stage}/commitment_loss\", info0['commitment_loss'], on_epoch=True, on_step=False)\n",
    "            self.log(f\"{stage}/reconstruction_loss\", info0['reconstruction_loss'], on_epoch=True, on_step=False)\n",
    "        self.log(\n",
    "            f\"{stage}/n\",\n",
    "            float(len(y)),\n",
    "            on_epoch=True,\n",
    "            on_step=False,\n",
    "            reduce_fx=torch.sum,\n",
    "        )\n",
    "        \n",
    "        if self._ae_mode == 0:\n",
    "            assert torch.isfinite(rec_loss), \"rec_loss is not finite\"\n",
    "            return rec_loss\n",
    "        elif self._ae_mode == 1:\n",
    "            assert torch.isfinite(pred_loss), \"pred_loss is not finite\"\n",
    "            return pred_loss\n",
    "        elif self._ae_mode == 2:\n",
    "            # , train/loss_pred_epoch=0.0195, train/loss_rec_epoch=169.0\n",
    "            assert torch.isfinite(pred_loss), \"pred_loss is not finite\"\n",
    "            assert torch.isfinite(rec_loss), \"rec_loss is not finite\"\n",
    "            return pred_loss * 50000 + rec_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dl_train), len(dl_val))\n",
    "b = next(iter(dl_train))\n",
    "x, y = b  # b['X'], b['y']\n",
    "print(x.shape, \"x\")\n",
    "if x.ndim == 3:\n",
    "    x = x.unsqueeze(-1)\n",
    "c_in = x.shape[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = PLAE(\n",
    "    c_in=c_in,\n",
    "    steps_per_epoch=len(dl_train),\n",
    "    max_epochs=max_epochs,\n",
    "    lr=lr,\n",
    "    encoder_sizes=[64,64,64,64],\n",
    "    weight_decay=wd,\n",
    "    n_latent=256,  # there will be layers * n_latent latent features\n",
    "    importance_matrix=importance_matrix,\n",
    "    tokens_per_layer=12\n",
    ")\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c_in)\n",
    "x1 = x[..., 0]\n",
    "with torch.no_grad():\n",
    "    y = net(x1)\n",
    "# {k: v.abs().mean() for k, v in y.items()}, {k: v.shape for k, v in y.items()}\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(net, input_data=x1, depth=4, col_names=(\"input_size\", \"output_size\", \"num_params\",))  # input_size=(batch_size, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     o = net.predict_step(b)\n",
    "#     l1_loss, l2_loss, loss, acts, h_reconstructed = net.ae(b[0])\n",
    "#     # l1_loss, l2_loss, loss, latent, h_rec = self.ae(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.ae_mode(0)\n",
    "trainer1 = pl.Trainer(\n",
    "    precision=\"16-mixed\",\n",
    "    gradient_clip_val=20,\n",
    "    accelerator=\"auto\",\n",
    "    devices=\"1\",\n",
    "    max_epochs=max_epochs,  # * VAE_EPOCH_MULT,\n",
    "    log_every_n_steps=1,\n",
    "    enable_progress_bar=verbose,\n",
    "    # enable_model_summary=verbose,\n",
    ")\n",
    "\n",
    "# LOAD_CHECKPONT = Path('/media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/notebooks/lightning_logs/version_52/1_ae.ckpt')\n",
    "LOAD_CHECKPONT = None\n",
    "if LOAD_CHECKPONT:\n",
    "    PLAE.load_from_checkpoint(LOAD_CHECKPONT)\n",
    "else:\n",
    "    trainer1.fit(model=net, train_dataloaders=dl_train, val_dataloaders=dl_val)\n",
    "    df_hist, df_hist_step = read_metrics_csv(\n",
    "        trainer1.logger.experiment.metrics_file_path\n",
    "    )\n",
    "    plot_hist(df_hist, [\"reconstruction_loss\", \"commitment_loss\", \"loss_rec\"], logy=True)\n",
    "    # plt.show()\n",
    "    # plot_hist(df_hist_step, ['loss_rec_step'], logy=True)\n",
    "\n",
    "    display(df_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_hist(df_hist, [\"reconstruction_loss\", \"commitment_loss\", \"loss_rec\"], logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist, df_hist_step = read_metrics_csv(trainer1.logger.experiment.metrics_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs3r = trainer1.test(\n",
    "    net, dataloaders=[dl_train, dl_val, dl_test, dl_ood], verbose=False\n",
    ")\n",
    "rs3 = rename_pl_test_results(rs3r, [\"train\", \"val\", \"test\", \"ood\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x[..., 0]\n",
    "with torch.no_grad():\n",
    "    y = net(x1)\n",
    "\n",
    "print('QC: view latent')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('z before quant')\n",
    "plot_latent(y['z'][..., 0]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('z_q after embed(z.argmin())')\n",
    "latent = y[\"latent\"].cpu()  # .reshape(64, 24, 12) # [Batch, Latent, Layer]\n",
    "plot_latent(latent[..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity = ((latent!=0) * 1.0).mean()\n",
    "print(f'QC: latent usage {sparsity:2.2%}')\n",
    "# sparsity_mult = y['l1_losses']/y['l1_raw']\n",
    "# print(f'QC: sparsity multiplier per layer {sparsity_mult.mean(0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z_q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME :bug: they should all be diff it's [batch, layer]\n",
    "# ok so the original had 4 inner pixels and one token per pixel [1, 64, 4, 4]\n",
    "# while we have [512, 1, 1]\n",
    "y['tokens']\n",
    "# wait we shouldn't have a single token for each layer... hmm something is wrong here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.ae_mode(1)\n",
    "trainer2 = pl.Trainer(\n",
    "    # precision=\"16-mixed\",\n",
    "    gradient_clip_val=20,\n",
    "    max_epochs=max_epochs,\n",
    "    log_every_n_steps=1,\n",
    "    enable_progress_bar=verbose,\n",
    "    enable_model_summary=verbose,\n",
    "    # callbacks=[lr_logger],\n",
    ")\n",
    "trainer2.fit(model=net, train_dataloaders=dl_train, val_dataloaders=dl_val);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist, _ = read_metrics_csv(trainer2.logger.experiment.metrics_file_path)\n",
    "plot_hist(df_hist, [\"loss_pred_epoch\", \"auroc\"])\n",
    "df_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs3r = trainer2.test(\n",
    "    net, dataloaders=[dl_train, dl_val, dl_test, dl_ood], verbose=False\n",
    ")\n",
    "rs3 = rename_pl_test_results(rs3r, [\"train\", \"val\", \"test\", \"ood\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = calc_metrics(dm, net, split=\"test\", verbose=False)\n",
    "b = calc_metrics(dm, net, split=\"val\", verbose=False)\n",
    "c = calc_metrics(dm_ood, net, split=\"all\", verbose=False)\n",
    "df_metrics = pd.DataFrame([a, b, c], index=[\"test\", \"val\", \"ood\"]).iloc[:, :3]\n",
    "print(df_metrics.round(2).to_markdown())\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train end-to-end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 / 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.ae_mode(2)\n",
    "trainer3 = pl.Trainer(\n",
    "    precision=\"16-mixed\",\n",
    "    gradient_clip_val=20,\n",
    "    max_epochs=max_epochs,\n",
    "    log_every_n_steps=3,\n",
    "    # enable_progress_bar=False, enable_model_summary=False\n",
    ")\n",
    "trainer3.fit(model=net, train_dataloaders=dl_train, val_dataloaders=dl_val)\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds2df(dm.dm_orig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at hist\n",
    "df_hist, _ = read_metrics_csv(trainer3.logger.experiment.metrics_file_path)\n",
    "plot_hist(df_hist, [\"loss_pred\", \"acc\"])\n",
    "\n",
    "rs3r = trainer3.test(\n",
    "    net, dataloaders=[dl_train, dl_val, dl_test, dl_ood], verbose=False\n",
    ")\n",
    "rs3 = rename_pl_test_results(rs3r, [\"train\", \"val\", \"test\", \"ood\"])\n",
    "\n",
    "# predict\n",
    "a = calc_metrics(dm, net, trainer1, \"test\")\n",
    "b = calc_metrics(dm, net, trainer1, \"val\")\n",
    "pd.DataFrame([a, b], index=[\"test\", \"val\"])\n",
    "\n",
    "c = calc_metrics(dm_ood, net, trainer1, \"all\")\n",
    "pd.DataFrame([a, b, c], index=[\"test\", \"val\", \"ood\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = calc_metrics(dm, net, trainer1, \"test\")\n",
    "b = calc_metrics(dm, net, trainer1, \"val\")\n",
    "c = calc_metrics(dm_ood, net, trainer1, \"all\")\n",
    "df_metrics = pd.DataFrame([a, b, c], index=[\"test\", \"val\", \"ood\"]).iloc[:, :3]\n",
    "print(df_metrics.round(3).to_markdown())\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
